{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Judy-Choi/Tensorflow_Certificate/blob/main/8_horse_human(data_gen).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Goal Metric\n",
        "- val_loss : 0.028\n",
        "- val_acc : 0.99"
      ],
      "metadata": {
        "id": "YuhlokzsS1up"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1boG3Cqd6cl"
      },
      "source": [
        "import tensorflow as tf\n",
        "import urllib\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYw42Rtjd99f"
      },
      "source": [
        "_TRAIN_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/horse-or-human.zip\"\n",
        "_TEST_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/validation-horse-or-human.zip\"\n",
        "urllib.request.urlretrieve(_TRAIN_URL, 'horse-or-human.zip')\n",
        "local_zip = 'horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('tmp/horse-or-human/')\n",
        "zip_ref.close()\n",
        "urllib.request.urlretrieve(_TEST_URL, 'validation-horse-or-human.zip')\n",
        "local_zip = 'validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('tmp/validation-horse-or-human/')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKDG8FKFfPH6",
        "outputId": "4fa7ea89-6296-48ec-aa93-dcda1add2903"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1 / 255,\n",
        "        rotation_range=40,        # degree range for random rotations\n",
        "        width_shift_range=0.2,    # fraction of total width\n",
        "        height_shift_range=0.2,   # fraction of total height\n",
        "        shear_range=0.2,          # shear angle in counter-clockwise direction\n",
        "        zoom_range=0.2,           # zoom \n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "        )\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255) \n",
        "\n",
        "TRAINING_DIR =  'tmp/horse-or-human/'\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        TRAINING_DIR, \n",
        "        target_size=(300, 300), \n",
        "        class_mode='binary' # catagorical for more than 2\n",
        "       )\n",
        "\n",
        "VALIDATION_DIR = 'tmp/validation-horse-or-human/'\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        VALIDATION_DIR, \n",
        "        target_size=(300, 300), \n",
        "        class_mode='binary',\n",
        "        )\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XQixGkcfvZT"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "        Conv2D(16, (3, 3), input_shape=(300, 300, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Flatten(), \n",
        "        Dropout(0.5),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y8MWw8Bf3nP",
        "outputId": "be1f56e4-5639-4f73-e47b-f483778a1a6f"
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "checkpoint_path = 'my_checkpoint.ckpt'\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, \n",
        "                             save_best_only=True, \n",
        "                             save_weights_only=True, \n",
        "                             monitor='val_loss', \n",
        "                             verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "history = model.fit( train_generator, \n",
        "        validation_data=(validation_generator),\n",
        "        epochs=50,\n",
        "        callbacks=[checkpoint, early_stopping]\n",
        "    )\n",
        "model.load_weights(checkpoint_path) \n",
        "model.save(\"horse-human(gen).h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5131\n",
            "Epoch 1: val_loss improved from inf to 0.69218, saving model to my_checkpoint.ckpt\n",
            "33/33 [==============================] - 40s 810ms/step - loss: 0.6935 - accuracy: 0.5131 - val_loss: 0.6922 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.6839 - accuracy: 0.5998\n",
            "Epoch 2: val_loss improved from 0.69218 to 0.68332, saving model to my_checkpoint.ckpt\n",
            "33/33 [==============================] - 27s 802ms/step - loss: 0.6839 - accuracy: 0.5998 - val_loss: 0.6833 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.6062 - accuracy: 0.6534\n",
            "Epoch 3: val_loss did not improve from 0.68332\n",
            "33/33 [==============================] - 26s 792ms/step - loss: 0.6062 - accuracy: 0.6534 - val_loss: 1.0725 - val_accuracy: 0.5352\n",
            "Epoch 4/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.5151 - accuracy: 0.7478\n",
            "Epoch 4: val_loss did not improve from 0.68332\n",
            "33/33 [==============================] - 28s 847ms/step - loss: 0.5151 - accuracy: 0.7478 - val_loss: 1.2839 - val_accuracy: 0.6367\n",
            "Epoch 5/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.5022 - accuracy: 0.7722\n",
            "Epoch 5: val_loss did not improve from 0.68332\n",
            "33/33 [==============================] - 26s 791ms/step - loss: 0.5022 - accuracy: 0.7722 - val_loss: 2.4960 - val_accuracy: 0.5312\n",
            "Epoch 6/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.4473 - accuracy: 0.7965\n",
            "Epoch 6: val_loss did not improve from 0.68332\n",
            "33/33 [==============================] - 26s 793ms/step - loss: 0.4473 - accuracy: 0.7965 - val_loss: 3.0489 - val_accuracy: 0.5195\n",
            "Epoch 7/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.3995 - accuracy: 0.8413\n",
            "Epoch 7: val_loss did not improve from 0.68332\n",
            "33/33 [==============================] - 26s 791ms/step - loss: 0.3995 - accuracy: 0.8413 - val_loss: 3.3276 - val_accuracy: 0.5156\n",
            "Epoch 8/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.4638 - accuracy: 0.7653\n",
            "Epoch 8: val_loss improved from 0.68332 to 0.62511, saving model to my_checkpoint.ckpt\n",
            "33/33 [==============================] - 26s 791ms/step - loss: 0.4638 - accuracy: 0.7653 - val_loss: 0.6251 - val_accuracy: 0.6250\n",
            "Epoch 9/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.4238 - accuracy: 0.7858\n",
            "Epoch 9: val_loss did not improve from 0.62511\n",
            "33/33 [==============================] - 26s 791ms/step - loss: 0.4238 - accuracy: 0.7858 - val_loss: 2.0111 - val_accuracy: 0.5898\n",
            "Epoch 10/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.3077 - accuracy: 0.8724\n",
            "Epoch 10: val_loss did not improve from 0.62511\n",
            "33/33 [==============================] - 26s 802ms/step - loss: 0.3077 - accuracy: 0.8724 - val_loss: 3.3497 - val_accuracy: 0.5508\n",
            "Epoch 11/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.3218 - accuracy: 0.8793\n",
            "Epoch 11: val_loss improved from 0.62511 to 0.58096, saving model to my_checkpoint.ckpt\n",
            "33/33 [==============================] - 26s 801ms/step - loss: 0.3218 - accuracy: 0.8793 - val_loss: 0.5810 - val_accuracy: 0.7305\n",
            "Epoch 12/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2712 - accuracy: 0.8987\n",
            "Epoch 12: val_loss did not improve from 0.58096\n",
            "33/33 [==============================] - 27s 834ms/step - loss: 0.2712 - accuracy: 0.8987 - val_loss: 1.6266 - val_accuracy: 0.5977\n",
            "Epoch 13/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2087 - accuracy: 0.9211\n",
            "Epoch 13: val_loss did not improve from 0.58096\n",
            "33/33 [==============================] - 26s 789ms/step - loss: 0.2087 - accuracy: 0.9211 - val_loss: 1.8943 - val_accuracy: 0.5820\n",
            "Epoch 14/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1953 - accuracy: 0.9387\n",
            "Epoch 14: val_loss did not improve from 0.58096\n",
            "33/33 [==============================] - 26s 784ms/step - loss: 0.1953 - accuracy: 0.9387 - val_loss: 1.8027 - val_accuracy: 0.5664\n",
            "Epoch 15/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1976 - accuracy: 0.9211\n",
            "Epoch 15: val_loss did not improve from 0.58096\n",
            "33/33 [==============================] - 26s 790ms/step - loss: 0.1976 - accuracy: 0.9211 - val_loss: 1.6814 - val_accuracy: 0.6055\n",
            "Epoch 16/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1246 - accuracy: 0.9552\n",
            "Epoch 16: val_loss did not improve from 0.58096\n",
            "33/33 [==============================] - 26s 784ms/step - loss: 0.1246 - accuracy: 0.9552 - val_loss: 2.7351 - val_accuracy: 0.5781\n",
            "Epoch 17/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0936 - accuracy: 0.9688\n",
            "Epoch 17: val_loss did not improve from 0.58096\n",
            "33/33 [==============================] - 27s 831ms/step - loss: 0.0936 - accuracy: 0.9688 - val_loss: 1.6101 - val_accuracy: 0.6445\n",
            "Epoch 18/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1411 - accuracy: 0.9513\n",
            "Epoch 18: val_loss did not improve from 0.58096\n",
            "33/33 [==============================] - 26s 793ms/step - loss: 0.1411 - accuracy: 0.9513 - val_loss: 3.7075 - val_accuracy: 0.5586\n",
            "Epoch 19/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1226 - accuracy: 0.9572\n",
            "Epoch 19: val_loss did not improve from 0.58096\n",
            "33/33 [==============================] - 26s 788ms/step - loss: 0.1226 - accuracy: 0.9572 - val_loss: 1.9821 - val_accuracy: 0.6250\n",
            "Epoch 20/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1100 - accuracy: 0.9630\n",
            "Epoch 20: val_loss did not improve from 0.58096\n",
            "33/33 [==============================] - 26s 783ms/step - loss: 0.1100 - accuracy: 0.9630 - val_loss: 2.0233 - val_accuracy: 0.6016\n",
            "Epoch 21/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1034 - accuracy: 0.9620\n",
            "Epoch 21: val_loss did not improve from 0.58096\n",
            "33/33 [==============================] - 26s 778ms/step - loss: 0.1034 - accuracy: 0.9620 - val_loss: 2.6052 - val_accuracy: 0.5781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 1 : CNN - 0.37534"
      ],
      "metadata": {
        "id": "cP8Q17miLLaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# There are 5 questions in this exam with increasing difficulty from 1-5.\n",
        "# Please note that the weight of the grade for the question is relative\n",
        "# to its difficulty. So your Category 1 question will score significantly\n",
        "# less than your Category 5 question.\n",
        "#\n",
        "# Don't use lambda layers in your model.\n",
        "# You do not need them to solve the question.\n",
        "# Lambda layers are not supported by the grading infrastructure.\n",
        "#\n",
        "# You must use the Submit and Test button to submit your model\n",
        "# at least once in this category before you finally submit your exam,\n",
        "# otherwise you will score zero for this category.\n",
        "# ======================================================================\n",
        "#\n",
        "# Computer vision with CNNs\n",
        "#\n",
        "# Create and train a classifier for horses or humans using the provided data.\n",
        "# Make sure your final layer is a 1 neuron, activated by sigmoid as shown.\n",
        "#\n",
        "# The test will use images that are 300x300 with 3 bytes color depth so be sure to\n",
        "# design your neural network accordingly\n",
        "\n",
        "import tensorflow as tf\n",
        "import urllib\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "def solution_model():\n",
        "    _TRAIN_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/horse-or-human.zip\"\n",
        "    _TEST_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/validation-horse-or-human.zip\"\n",
        "    urllib.request.urlretrieve(_TRAIN_URL, 'horse-or-human.zip')\n",
        "    local_zip = 'horse-or-human.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "    zip_ref.extractall('tmp/horse-or-human/')\n",
        "    zip_ref.close()\n",
        "    urllib.request.urlretrieve(_TEST_URL, 'validation-horse-or-human.zip')\n",
        "    local_zip = 'validation-horse-or-human.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "    zip_ref.extractall('tmp/validation-horse-or-human/')\n",
        "    zip_ref.close()\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        #Your code here. Should at least have a rescale. Other parameters can help with overfitting.)\n",
        "                rescale=1 / 255,\n",
        "        rotation_range=40,        # degree range for random rotations\n",
        "        width_shift_range=0.2,    # fraction of total width\n",
        "        height_shift_range=0.2,   # fraction of total height\n",
        "        shear_range=0.2,          # shear angle in counter-clockwise direction\n",
        "        zoom_range=0.2,           # zoom \n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "        )\n",
        "    \n",
        "    # validation_datagen = ImageDataGenerator(#Your Code here)\n",
        "    validation_datagen = ImageDataGenerator(rescale = 1./255) \n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        #Your Code Here)\n",
        "        'tmp/horse-or-human/', \n",
        "        target_size=(300, 300), \n",
        "        class_mode='binary' # catagorical for more than 2\n",
        "       )\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        #Your Code Here)\n",
        "        'tmp/validation-horse-or-human/', \n",
        "        target_size=(300, 300), \n",
        "        class_mode='binary',\n",
        "        )\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "        # Note the input shape specified on your first layer must be (300,300,3)\n",
        "        # Your Code here\n",
        "        Conv2D(16, (3, 3), input_shape=(300, 300, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Flatten(), \n",
        "        Dropout(0.5),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "\n",
        "        # This is the last layer. You should not change this code.\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # model.compile(#Your Code Here#)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Callback function\n",
        "    checkpoint = ModelCheckpoint('my_checkpoint.ckpt', \n",
        "                                save_best_only=True, \n",
        "                                save_weights_only=True, \n",
        "                                monitor='val_loss', \n",
        "                                verbose=1)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "    # NOTE: If training is taking a very long time, you should consider setting the batch size\n",
        "    # appropriately on the generator, and the steps per epoch in the model.fit() function.\n",
        "    # model.fit(#Your Code Here#)\n",
        "    history = model.fit( train_generator, \n",
        "        validation_data=(validation_generator),\n",
        "        epochs=50,\n",
        "        callbacks=[checkpoint, early_stopping]\n",
        "    )\n",
        "\n",
        "    return model   \n",
        "    \n",
        "# Note that you'll need to save your model as a .h5 like this.\n",
        "# When you press the Submit and Test button, your saved .h5 model will\n",
        "# be sent to the testing infrastructure for scoring\n",
        "# and the score will be returned to you.\n",
        "if __name__ == '__main__':\n",
        "    model = solution_model()\n",
        "    # load best ck\n",
        "    model.load_weights('my_checkpoint.ckpt')\n",
        "    model.save(\"mymodel.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyNy5J0fLMMV",
        "outputId": "b4488fb2-a86e-46de-e2e3-e168091f15d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n",
            "Epoch 1/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.6912 - accuracy: 0.5326\n",
            "Epoch 1: val_loss improved from inf to 0.66799, saving model to my_checkpoint.ckpt\n",
            "33/33 [==============================] - 40s 795ms/step - loss: 0.6912 - accuracy: 0.5326 - val_loss: 0.6680 - val_accuracy: 0.6992\n",
            "Epoch 2/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.5979 - accuracy: 0.6767\n",
            "Epoch 2: val_loss did not improve from 0.66799\n",
            "33/33 [==============================] - 26s 798ms/step - loss: 0.5979 - accuracy: 0.6767 - val_loss: 1.0540 - val_accuracy: 0.5391\n",
            "Epoch 3/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.5206 - accuracy: 0.7400\n",
            "Epoch 3: val_loss improved from 0.66799 to 0.66227, saving model to my_checkpoint.ckpt\n",
            "33/33 [==============================] - 26s 790ms/step - loss: 0.5206 - accuracy: 0.7400 - val_loss: 0.6623 - val_accuracy: 0.7578\n",
            "Epoch 4/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.4844 - accuracy: 0.7858\n",
            "Epoch 4: val_loss did not improve from 0.66227\n",
            "33/33 [==============================] - 26s 792ms/step - loss: 0.4844 - accuracy: 0.7858 - val_loss: 1.2999 - val_accuracy: 0.6562\n",
            "Epoch 5/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.4049 - accuracy: 0.8257\n",
            "Epoch 5: val_loss did not improve from 0.66227\n",
            "33/33 [==============================] - 28s 865ms/step - loss: 0.4049 - accuracy: 0.8257 - val_loss: 1.4812 - val_accuracy: 0.7109\n",
            "Epoch 6/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.3663 - accuracy: 0.8364\n",
            "Epoch 6: val_loss improved from 0.66227 to 0.47419, saving model to my_checkpoint.ckpt\n",
            "33/33 [==============================] - 27s 809ms/step - loss: 0.3663 - accuracy: 0.8364 - val_loss: 0.4742 - val_accuracy: 0.8281\n",
            "Epoch 7/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.4455 - accuracy: 0.8121\n",
            "Epoch 7: val_loss did not improve from 0.47419\n",
            "33/33 [==============================] - 26s 793ms/step - loss: 0.4455 - accuracy: 0.8121 - val_loss: 1.1843 - val_accuracy: 0.6992\n",
            "Epoch 8/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.3060 - accuracy: 0.8734\n",
            "Epoch 8: val_loss did not improve from 0.47419\n",
            "33/33 [==============================] - 26s 792ms/step - loss: 0.3060 - accuracy: 0.8734 - val_loss: 1.3552 - val_accuracy: 0.6836\n",
            "Epoch 9/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2478 - accuracy: 0.8978\n",
            "Epoch 9: val_loss did not improve from 0.47419\n",
            "33/33 [==============================] - 26s 785ms/step - loss: 0.2478 - accuracy: 0.8978 - val_loss: 3.7964 - val_accuracy: 0.5703\n",
            "Epoch 10/50\n",
            "32/33 [============================>.] - ETA: 0s - loss: 0.2908 - accuracy: 0.8730\n",
            "Epoch 10: val_loss improved from 0.47419 to 0.37534, saving model to my_checkpoint.ckpt\n",
            "33/33 [==============================] - 26s 789ms/step - loss: 0.2917 - accuracy: 0.8724 - val_loss: 0.3753 - val_accuracy: 0.8750\n",
            "Epoch 11/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2755 - accuracy: 0.8822\n",
            "Epoch 11: val_loss did not improve from 0.37534\n",
            "33/33 [==============================] - 26s 786ms/step - loss: 0.2755 - accuracy: 0.8822 - val_loss: 2.8238 - val_accuracy: 0.6250\n",
            "Epoch 12/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2087 - accuracy: 0.9202\n",
            "Epoch 12: val_loss did not improve from 0.37534\n",
            "33/33 [==============================] - 27s 808ms/step - loss: 0.2087 - accuracy: 0.9202 - val_loss: 0.7020 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2074 - accuracy: 0.9143\n",
            "Epoch 13: val_loss did not improve from 0.37534\n",
            "33/33 [==============================] - 28s 859ms/step - loss: 0.2074 - accuracy: 0.9143 - val_loss: 1.5174 - val_accuracy: 0.6133\n",
            "Epoch 14/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1603 - accuracy: 0.9387\n",
            "Epoch 14: val_loss did not improve from 0.37534\n",
            "33/33 [==============================] - 30s 918ms/step - loss: 0.1603 - accuracy: 0.9387 - val_loss: 2.3138 - val_accuracy: 0.6680\n",
            "Epoch 15/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1871 - accuracy: 0.9309\n",
            "Epoch 15: val_loss did not improve from 0.37534\n",
            "33/33 [==============================] - 29s 888ms/step - loss: 0.1871 - accuracy: 0.9309 - val_loss: 1.1678 - val_accuracy: 0.7188\n",
            "Epoch 16/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1389 - accuracy: 0.9494\n",
            "Epoch 16: val_loss did not improve from 0.37534\n",
            "33/33 [==============================] - 27s 808ms/step - loss: 0.1389 - accuracy: 0.9494 - val_loss: 2.2589 - val_accuracy: 0.6445\n",
            "Epoch 17/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1201 - accuracy: 0.9581\n",
            "Epoch 17: val_loss did not improve from 0.37534\n",
            "33/33 [==============================] - 27s 818ms/step - loss: 0.1201 - accuracy: 0.9581 - val_loss: 1.5713 - val_accuracy: 0.6992\n",
            "Epoch 18/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1156 - accuracy: 0.9611\n",
            "Epoch 18: val_loss did not improve from 0.37534\n",
            "33/33 [==============================] - 26s 797ms/step - loss: 0.1156 - accuracy: 0.9611 - val_loss: 1.9181 - val_accuracy: 0.6719\n",
            "Epoch 19/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1746 - accuracy: 0.9299\n",
            "Epoch 19: val_loss did not improve from 0.37534\n",
            "33/33 [==============================] - 29s 895ms/step - loss: 0.1746 - accuracy: 0.9299 - val_loss: 1.1183 - val_accuracy: 0.7148\n",
            "Epoch 20/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1351 - accuracy: 0.9513\n",
            "Epoch 20: val_loss did not improve from 0.37534\n",
            "33/33 [==============================] - 30s 899ms/step - loss: 0.1351 - accuracy: 0.9513 - val_loss: 1.5241 - val_accuracy: 0.7461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 2 : Transfer Learning - 0.01681"
      ],
      "metadata": {
        "id": "76rfBc36UEMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# There are 5 questions in this exam with increasing difficulty from 1-5.\n",
        "# Please note that the weight of the grade for the question is relative\n",
        "# to its difficulty. So your Category 1 question will score significantly\n",
        "# less than your Category 5 question.\n",
        "#\n",
        "# Don't use lambda layers in your model.\n",
        "# You do not need them to solve the question.\n",
        "# Lambda layers are not supported by the grading infrastructure.\n",
        "#\n",
        "# You must use the Submit and Test button to submit your model\n",
        "# at least once in this category before you finally submit your exam,\n",
        "# otherwise you will score zero for this category.\n",
        "# ======================================================================\n",
        "#\n",
        "# Computer vision with CNNs\n",
        "#\n",
        "# Create and train a classifier for horses or humans using the provided data.\n",
        "# Make sure your final layer is a 1 neuron, activated by sigmoid as shown.\n",
        "#\n",
        "# The test will use images that are 300x300 with 3 bytes color depth so be sure to\n",
        "# design your neural network accordingly\n",
        "\n",
        "import tensorflow as tf\n",
        "import urllib\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "# VGG16\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "def solution_model():\n",
        "    _TRAIN_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/horse-or-human.zip\"\n",
        "    _TEST_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/validation-horse-or-human.zip\"\n",
        "    urllib.request.urlretrieve(_TRAIN_URL, 'horse-or-human.zip')\n",
        "    local_zip = 'horse-or-human.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "    zip_ref.extractall('tmp/horse-or-human/')\n",
        "    zip_ref.close()\n",
        "    urllib.request.urlretrieve(_TEST_URL, 'validation-horse-or-human.zip')\n",
        "    local_zip = 'validation-horse-or-human.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "    zip_ref.extractall('tmp/validation-horse-or-human/')\n",
        "    zip_ref.close()\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        #Your code here. Should at least have a rescale. Other parameters can help with overfitting.)\n",
        "                rescale=1 / 255,\n",
        "        rotation_range=40,        # degree range for random rotations\n",
        "        width_shift_range=0.2,    # fraction of total width\n",
        "        height_shift_range=0.2,   # fraction of total height\n",
        "        shear_range=0.2,          # shear angle in counter-clockwise direction\n",
        "        zoom_range=0.2,           # zoom \n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "        )\n",
        "    \n",
        "    # validation_datagen = ImageDataGenerator(#Your Code here)\n",
        "    validation_datagen = ImageDataGenerator(rescale = 1./255) \n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        #Your Code Here)\n",
        "        'tmp/horse-or-human/', \n",
        "        target_size=(300, 300), \n",
        "        class_mode='binary' # catagorical for more than 2\n",
        "       )\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        #Your Code Here)\n",
        "        'tmp/validation-horse-or-human/', \n",
        "        target_size=(300, 300), \n",
        "        class_mode='binary',\n",
        "        )\n",
        "    \n",
        "    transfer_model = VGG16(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
        "    transfer_model.trainable=False\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "        # Note the input shape specified on your first layer must be (300,300,3)\n",
        "        # Your Code here\n",
        "        transfer_model,\n",
        "        Flatten(), \n",
        "        Dropout(0.5),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "\n",
        "        # This is the last layer. You should not change this code.\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # model.compile(#Your Code Here#)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Callback function\n",
        "    checkpoint = ModelCheckpoint('my_checkpoint.ckpt', \n",
        "                                save_best_only=True, \n",
        "                                save_weights_only=True, \n",
        "                                monitor='val_loss', \n",
        "                                verbose=1)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "    # NOTE: If training is taking a very long time, you should consider setting the batch size\n",
        "    # appropriately on the generator, and the steps per epoch in the model.fit() function.\n",
        "    # model.fit(#Your Code Here#)\n",
        "    history = model.fit( train_generator, \n",
        "        validation_data=(validation_generator),\n",
        "        epochs=50,\n",
        "        callbacks=[checkpoint, early_stopping]\n",
        "    )\n",
        "\n",
        "    return model   \n",
        "    \n",
        "# Note that you'll need to save your model as a .h5 like this.\n",
        "# When you press the Submit and Test button, your saved .h5 model will\n",
        "# be sent to the testing infrastructure for scoring\n",
        "# and the score will be returned to you.\n",
        "if __name__ == '__main__':\n",
        "    model = solution_model()\n",
        "    # load best ck\n",
        "    model.load_weights('my_checkpoint.ckpt')\n",
        "    model.save(\"mymodel.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdBYFyzuRIr7",
        "outputId": "42fd2797-e36d-4670-d0c0-d53856bcd258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 2s 0us/step\n",
            "Epoch 1/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.6333 - accuracy: 0.8082\n",
            "Epoch 1: val_loss improved from inf to 0.30970, saving model to my_checkpoint.ckpt\n",
            "33/33 [==============================] - 42s 1000ms/step - loss: 0.6333 - accuracy: 0.8082 - val_loss: 0.3097 - val_accuracy: 0.8672\n",
            "Epoch 2/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0752 - accuracy: 0.9786\n",
            "Epoch 2: val_loss did not improve from 0.30970\n",
            "33/33 [==============================] - 30s 914ms/step - loss: 0.0752 - accuracy: 0.9786 - val_loss: 0.3228 - val_accuracy: 0.8945\n",
            "Epoch 3/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.9757\n",
            "Epoch 3: val_loss improved from 0.30970 to 0.16630, saving model to my_checkpoint.ckpt\n",
            "33/33 [==============================] - 32s 940ms/step - loss: 0.0609 - accuracy: 0.9757 - val_loss: 0.1663 - val_accuracy: 0.9414\n",
            "Epoch 4/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 0.9766\n",
            "Epoch 4: val_loss did not improve from 0.16630\n",
            "33/33 [==============================] - 31s 940ms/step - loss: 0.0610 - accuracy: 0.9766 - val_loss: 0.3876 - val_accuracy: 0.8828\n",
            "Epoch 5/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.9747\n",
            "Epoch 5: val_loss did not improve from 0.16630\n",
            "33/33 [==============================] - 31s 918ms/step - loss: 0.0783 - accuracy: 0.9747 - val_loss: 0.6221 - val_accuracy: 0.8477\n",
            "Epoch 6/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9718\n",
            "Epoch 6: val_loss did not improve from 0.16630\n",
            "33/33 [==============================] - 30s 902ms/step - loss: 0.0786 - accuracy: 0.9718 - val_loss: 0.2436 - val_accuracy: 0.9336\n",
            "Epoch 7/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9805\n",
            "Epoch 7: val_loss improved from 0.16630 to 0.01681, saving model to my_checkpoint.ckpt\n",
            "33/33 [==============================] - 30s 916ms/step - loss: 0.0505 - accuracy: 0.9805 - val_loss: 0.0168 - val_accuracy: 0.9961\n",
            "Epoch 8/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 0.9854\n",
            "Epoch 8: val_loss did not improve from 0.01681\n",
            "33/33 [==============================] - 29s 882ms/step - loss: 0.0521 - accuracy: 0.9854 - val_loss: 0.3113 - val_accuracy: 0.9297\n",
            "Epoch 9/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0702 - accuracy: 0.9737\n",
            "Epoch 9: val_loss did not improve from 0.01681\n",
            "33/33 [==============================] - 29s 871ms/step - loss: 0.0702 - accuracy: 0.9737 - val_loss: 0.2696 - val_accuracy: 0.9258\n",
            "Epoch 10/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9815\n",
            "Epoch 10: val_loss did not improve from 0.01681\n",
            "33/33 [==============================] - 31s 911ms/step - loss: 0.0489 - accuracy: 0.9815 - val_loss: 0.0552 - val_accuracy: 0.9688\n",
            "Epoch 11/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9922\n",
            "Epoch 11: val_loss did not improve from 0.01681\n",
            "33/33 [==============================] - 30s 891ms/step - loss: 0.0185 - accuracy: 0.9922 - val_loss: 0.1792 - val_accuracy: 0.9492\n",
            "Epoch 12/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 0.9883\n",
            "Epoch 12: val_loss did not improve from 0.01681\n",
            "33/33 [==============================] - 30s 910ms/step - loss: 0.0306 - accuracy: 0.9883 - val_loss: 0.6479 - val_accuracy: 0.8672\n",
            "Epoch 13/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9932\n",
            "Epoch 13: val_loss did not improve from 0.01681\n",
            "33/33 [==============================] - 30s 891ms/step - loss: 0.0197 - accuracy: 0.9932 - val_loss: 0.1468 - val_accuracy: 0.9453\n",
            "Epoch 14/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.9815\n",
            "Epoch 14: val_loss did not improve from 0.01681\n",
            "33/33 [==============================] - 29s 886ms/step - loss: 0.0615 - accuracy: 0.9815 - val_loss: 0.2713 - val_accuracy: 0.9258\n",
            "Epoch 15/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 0.9815\n",
            "Epoch 15: val_loss did not improve from 0.01681\n",
            "33/33 [==============================] - 30s 884ms/step - loss: 0.0427 - accuracy: 0.9815 - val_loss: 0.5174 - val_accuracy: 0.9023\n",
            "Epoch 16/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0623 - accuracy: 0.9747\n",
            "Epoch 16: val_loss did not improve from 0.01681\n",
            "33/33 [==============================] - 29s 876ms/step - loss: 0.0623 - accuracy: 0.9747 - val_loss: 0.1670 - val_accuracy: 0.9531\n",
            "Epoch 17/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9854\n",
            "Epoch 17: val_loss did not improve from 0.01681\n",
            "33/33 [==============================] - 30s 894ms/step - loss: 0.0302 - accuracy: 0.9854 - val_loss: 0.3664 - val_accuracy: 0.9141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 3 : ChatGPT(CNN) - 0.69302\n",
        "\n",
        "다음 코드를 최적화해 줘,  \n",
        "단, 다음 조건을 적용해 줘  \n",
        "Use dropout  \n",
        "Use batch normalization  \n",
        "Use checkpoint with save best only, and save weight only and verbose = 1  \n",
        "Use early stopping with patience = 10  \n",
        "Use reduce learning rate on plateau  \n",
        "set verbose = 1  \n",
        "Set epochs = 50  \n",
        "do not use data augmentation  \n",
        "Use other methods to make val loss value lower.  "
      ],
      "metadata": {
        "id": "qbr27V15U9qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# There are 5 questions in this exam with increasing difficulty from 1-5.\n",
        "# Please note that the weight of the grade for the question is relative\n",
        "# to its difficulty. So your Category 1 question will score significantly\n",
        "# less than your Category 5 question.\n",
        "#\n",
        "# Don't use lambda layers in your model.\n",
        "# You do not need them to solve the question.\n",
        "# Lambda layers are not supported by the grading infrastructure.\n",
        "#\n",
        "# You must use the Submit and Test button to submit your model\n",
        "# at least once in this category before you finally submit your exam,\n",
        "# otherwise you will score zero for this category.\n",
        "# ======================================================================\n",
        "#\n",
        "# Computer vision with CNNs\n",
        "#\n",
        "# Create and train a classifier for horses or humans using the provided data.\n",
        "# Make sure your final layer is a 1 neuron, activated by sigmoid as shown.\n",
        "#\n",
        "# The test will use images that are 300x300 with 3 bytes color depth so be sure to\n",
        "# design your neural network accordingly\n",
        "\n",
        "import tensorflow as tf\n",
        "import urllib\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "def solution_model():\n",
        "    _TRAIN_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/horse-or-human.zip\"\n",
        "    _TEST_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/validation-horse-or-human.zip\"\n",
        "    urllib.request.urlretrieve(_TRAIN_URL, 'horse-or-human.zip')\n",
        "    local_zip = 'horse-or-human.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "    zip_ref.extractall('tmp/horse-or-human/')\n",
        "    zip_ref.close()\n",
        "    urllib.request.urlretrieve(_TEST_URL, 'validation-horse-or-human.zip')\n",
        "    local_zip = 'validation-horse-or-human.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "    zip_ref.extractall('tmp/validation-horse-or-human/')\n",
        "    zip_ref.close()\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        #Your code here. Should at least have a rescale. Other parameters can help with overfitting.)\n",
        "                rescale=1 / 255,\n",
        "        rotation_range=40,        # degree range for random rotations\n",
        "        width_shift_range=0.2,    # fraction of total width\n",
        "        height_shift_range=0.2,   # fraction of total height\n",
        "        shear_range=0.2,          # shear angle in counter-clockwise direction\n",
        "        zoom_range=0.2,           # zoom \n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "        )\n",
        "    \n",
        "    # validation_datagen = ImageDataGenerator(#Your Code here)\n",
        "    validation_datagen = ImageDataGenerator(rescale = 1./255) \n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        #Your Code Here)\n",
        "        'tmp/horse-or-human/', \n",
        "        target_size=(300, 300), \n",
        "        class_mode='binary' # catagorical for more than 2\n",
        "       )\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        #Your Code Here)\n",
        "        'tmp/validation-horse-or-human/', \n",
        "        target_size=(300, 300), \n",
        "        class_mode='binary',\n",
        "        )\n",
        "\n",
        "    model = Sequential([\n",
        "        Conv2D(16, (3, 3), input_shape=(300, 300, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Flatten(), \n",
        "        Dropout(0.5),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    checkpoint = ModelCheckpoint(\"best_model.h5\", save_best_only=True, save_weights_only=True, verbose=1)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1)\n",
        "\n",
        "    history = model.fit( train_generator, \n",
        "        validation_data=(validation_generator),\n",
        "        epochs=50,\n",
        "        callbacks=[checkpoint, early_stopping, reduce_lr]\n",
        "    )\n",
        "\n",
        "    return model   \n",
        "    \n",
        "# Note that you'll need to save your model as a .h5 like this.\n",
        "# When you press the Submit and Test button, your saved .h5 model will\n",
        "# be sent to the testing infrastructure for scoring\n",
        "# and the score will be returned to you.\n",
        "if __name__ == '__main__':\n",
        "    model = solution_model()\n",
        "    model.save(\"mymodel.h5\")"
      ],
      "metadata": {
        "id": "3EHgaOFNU-ov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d37646-4c2c-44fd-8808-6a4624c873f9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n",
            "Epoch 1/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.9305 - accuracy: 0.6086\n",
            "Epoch 1: val_loss improved from inf to 0.69302, saving model to best_model.h5\n",
            "33/33 [==============================] - 32s 805ms/step - loss: 0.9305 - accuracy: 0.6086 - val_loss: 0.6930 - val_accuracy: 0.4688 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.5064 - accuracy: 0.7653\n",
            "Epoch 2: val_loss did not improve from 0.69302\n",
            "33/33 [==============================] - 27s 814ms/step - loss: 0.5064 - accuracy: 0.7653 - val_loss: 0.7016 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.3893 - accuracy: 0.8257\n",
            "Epoch 3: val_loss did not improve from 0.69302\n",
            "33/33 [==============================] - 31s 949ms/step - loss: 0.3893 - accuracy: 0.8257 - val_loss: 0.8442 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.3321 - accuracy: 0.8695\n",
            "Epoch 4: val_loss did not improve from 0.69302\n",
            "33/33 [==============================] - 27s 823ms/step - loss: 0.3321 - accuracy: 0.8695 - val_loss: 0.9700 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2501 - accuracy: 0.9075\n",
            "Epoch 5: val_loss did not improve from 0.69302\n",
            "33/33 [==============================] - 27s 830ms/step - loss: 0.2501 - accuracy: 0.9075 - val_loss: 1.9146 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2482 - accuracy: 0.8939\n",
            "Epoch 6: val_loss did not improve from 0.69302\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "33/33 [==============================] - 27s 819ms/step - loss: 0.2482 - accuracy: 0.8939 - val_loss: 1.5205 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1762 - accuracy: 0.9387\n",
            "Epoch 7: val_loss did not improve from 0.69302\n",
            "33/33 [==============================] - 28s 833ms/step - loss: 0.1762 - accuracy: 0.9387 - val_loss: 1.7728 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1870 - accuracy: 0.9299\n",
            "Epoch 8: val_loss did not improve from 0.69302\n",
            "33/33 [==============================] - 27s 831ms/step - loss: 0.1870 - accuracy: 0.9299 - val_loss: 1.8521 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1403 - accuracy: 0.9484\n",
            "Epoch 9: val_loss did not improve from 0.69302\n",
            "33/33 [==============================] - 27s 811ms/step - loss: 0.1403 - accuracy: 0.9484 - val_loss: 1.7814 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1549 - accuracy: 0.9445\n",
            "Epoch 10: val_loss did not improve from 0.69302\n",
            "33/33 [==============================] - 29s 890ms/step - loss: 0.1549 - accuracy: 0.9445 - val_loss: 1.4349 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1448 - accuracy: 0.9523\n",
            "Epoch 11: val_loss did not improve from 0.69302\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "33/33 [==============================] - 29s 861ms/step - loss: 0.1448 - accuracy: 0.9523 - val_loss: 1.0402 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 11: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 4 : ChatGPT(ResNet50) - 0.62821\n",
        "\n",
        "이 코드의 cnn 을 Transfer Learning 으로 바꿔 줘. 단, 모델은 VGG16 이외의 모델을 적용해 줘\n",
        "\n",
        "위 코드에서는 ResNet50 모델을 불러와서 기존에 사용하던 Convolutional Layer들을 대체하고, Flatten() layer를 추가해주었습니다. 그리고 BatchNormalization()과 Dropout() layer를 추가하여 regularization을 수행합니다. 이 때, ResNet50의 layer들은 학습을 하지 않도록 freeze 시켜주어야 합니다. 모델 학습 시, 모델의 성능을 체크하기 위한 checkpoint와 early stopping, 그리고 val_loss 값이 개선되지 않을 경우 learning rate를 조정해주는 reduce_lr callback 함수를 적용하였습니다."
      ],
      "metadata": {
        "id": "MppNdjcXJhO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# There are 5 questions in this exam with increasing difficulty from 1-5.\n",
        "# Please note that the weight of the grade for the question is relative\n",
        "# to its difficulty. So your Category 1 question will score significantly\n",
        "# less than your Category 5 question.\n",
        "#\n",
        "# Don't use lambda layers in your model.\n",
        "# You do not need them to solve the question.\n",
        "# Lambda layers are not supported by the grading infrastructure.\n",
        "#\n",
        "# You must use the Submit and Test button to submit your model\n",
        "# at least once in this category before you finally submit your exam,\n",
        "# otherwise you will score zero for this category.\n",
        "# ======================================================================\n",
        "#\n",
        "# Computer vision with CNNs\n",
        "#\n",
        "# Create and train a classifier for horses or humans using the provided data.\n",
        "# Make sure your final layer is a 1 neuron, activated by sigmoid as shown.\n",
        "#\n",
        "# The test will use images that are 300x300 with 3 bytes color depth so be sure to\n",
        "# design your neural network accordingly\n",
        "\n",
        "import tensorflow as tf\n",
        "import urllib\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "def solution_model():\n",
        "    _TRAIN_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/horse-or-human.zip\"\n",
        "    _TEST_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/validation-horse-or-human.zip\"\n",
        "    urllib.request.urlretrieve(_TRAIN_URL, 'horse-or-human.zip')\n",
        "    local_zip = 'horse-or-human.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "    zip_ref.extractall('tmp/horse-or-human/')\n",
        "    zip_ref.close()\n",
        "    urllib.request.urlretrieve(_TEST_URL, 'validation-horse-or-human.zip')\n",
        "    local_zip = 'validation-horse-or-human.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "    zip_ref.extractall('tmp/validation-horse-or-human/')\n",
        "    zip_ref.close()\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        #Your code here. Should at least have a rescale. Other parameters can help with overfitting.)\n",
        "                rescale=1 / 255,\n",
        "        rotation_range=40,        # degree range for random rotations\n",
        "        width_shift_range=0.2,    # fraction of total width\n",
        "        height_shift_range=0.2,   # fraction of total height\n",
        "        shear_range=0.2,          # shear angle in counter-clockwise direction\n",
        "        zoom_range=0.2,           # zoom \n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "        )\n",
        "    \n",
        "    # validation_datagen = ImageDataGenerator(#Your Code here)\n",
        "    validation_datagen = ImageDataGenerator(rescale = 1./255) \n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        #Your Code Here)\n",
        "        'tmp/horse-or-human/', \n",
        "        target_size=(300, 300), \n",
        "        class_mode='binary' # catagorical for more than 2\n",
        "       )\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        #Your Code Here)\n",
        "        'tmp/validation-horse-or-human/', \n",
        "        target_size=(300, 300), \n",
        "        class_mode='binary',\n",
        "        )\n",
        "    \n",
        "    resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
        "\n",
        "    # Freeze the layers in the ResNet50 model\n",
        "    for layer in resnet.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Build the new model on top of the ResNet50 model\n",
        "    model = Sequential([\n",
        "        resnet,\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # 모델 컴파일\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # 모델 학습\n",
        "    checkpoint = ModelCheckpoint(\"best_model.h5\", save_best_only=True, save_weights_only=True, verbose=1)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1)\n",
        "\n",
        "    history = model.fit(train_generator, \n",
        "                        validation_data=validation_generator,\n",
        "                        epochs=50,\n",
        "                        callbacks=[checkpoint, early_stopping, reduce_lr],\n",
        "                        verbose=1)\n",
        "\n",
        "    return model   \n",
        "    \n",
        "# Note that you'll need to save your model as a .h5 like this.\n",
        "# When you press the Submit and Test button, your saved .h5 model will\n",
        "# be sent to the testing infrastructure for scoring\n",
        "# and the score will be returned to you.\n",
        "if __name__ == '__main__':\n",
        "    model = solution_model()\n",
        "    model.save(\"mymodel.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrSjrqRgGafG",
        "outputId": "683475d6-7808-4254-e32a-be8c33576b82"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n",
            "Epoch 1/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 21.3790 - accuracy: 0.5122\n",
            "Epoch 1: val_loss improved from inf to 1.18965, saving model to best_model.h5\n",
            "33/33 [==============================] - 37s 980ms/step - loss: 21.3790 - accuracy: 0.5122 - val_loss: 1.1896 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 6.7203 - accuracy: 0.5131\n",
            "Epoch 2: val_loss improved from 1.18965 to 0.71708, saving model to best_model.h5\n",
            "33/33 [==============================] - 32s 976ms/step - loss: 6.7203 - accuracy: 0.5131 - val_loss: 0.7171 - val_accuracy: 0.3047 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 2.2292 - accuracy: 0.4937\n",
            "Epoch 3: val_loss did not improve from 0.71708\n",
            "33/33 [==============================] - 31s 917ms/step - loss: 2.2292 - accuracy: 0.4937 - val_loss: 0.7350 - val_accuracy: 0.0664 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 1.6792 - accuracy: 0.4907\n",
            "Epoch 4: val_loss improved from 0.71708 to 0.69844, saving model to best_model.h5\n",
            "33/33 [==============================] - 32s 982ms/step - loss: 1.6792 - accuracy: 0.4907 - val_loss: 0.6984 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.9919 - accuracy: 0.5287\n",
            "Epoch 5: val_loss improved from 0.69844 to 0.67808, saving model to best_model.h5\n",
            "33/33 [==============================] - 32s 977ms/step - loss: 0.9919 - accuracy: 0.5287 - val_loss: 0.6781 - val_accuracy: 0.6602 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.9309 - accuracy: 0.5287\n",
            "Epoch 6: val_loss improved from 0.67808 to 0.63262, saving model to best_model.h5\n",
            "33/33 [==============================] - 32s 954ms/step - loss: 0.9309 - accuracy: 0.5287 - val_loss: 0.6326 - val_accuracy: 0.5352 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 1.0084 - accuracy: 0.5151\n",
            "Epoch 7: val_loss did not improve from 0.63262\n",
            "33/33 [==============================] - 30s 899ms/step - loss: 1.0084 - accuracy: 0.5151 - val_loss: 0.6789 - val_accuracy: 0.5820 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.7059 - accuracy: 0.5540\n",
            "Epoch 8: val_loss improved from 0.63262 to 0.62821, saving model to best_model.h5\n",
            "33/33 [==============================] - 32s 959ms/step - loss: 0.7059 - accuracy: 0.5540 - val_loss: 0.6282 - val_accuracy: 0.6406 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.6942 - accuracy: 0.5336\n",
            "Epoch 9: val_loss did not improve from 0.62821\n",
            "33/33 [==============================] - 30s 918ms/step - loss: 0.6942 - accuracy: 0.5336 - val_loss: 0.6588 - val_accuracy: 0.6523 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.6776 - accuracy: 0.5024\n",
            "Epoch 10: val_loss did not improve from 0.62821\n",
            "33/33 [==============================] - 29s 887ms/step - loss: 0.6776 - accuracy: 0.5024 - val_loss: 0.6545 - val_accuracy: 0.5781 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.6642 - accuracy: 0.5599\n",
            "Epoch 11: val_loss did not improve from 0.62821\n",
            "33/33 [==============================] - 30s 942ms/step - loss: 0.6642 - accuracy: 0.5599 - val_loss: 0.7692 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.8076 - accuracy: 0.5141\n",
            "Epoch 12: val_loss did not improve from 0.62821\n",
            "33/33 [==============================] - 29s 890ms/step - loss: 0.8076 - accuracy: 0.5141 - val_loss: 0.8273 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.7404 - accuracy: 0.5034\n",
            "Epoch 13: val_loss did not improve from 0.62821\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "33/33 [==============================] - 29s 891ms/step - loss: 0.7404 - accuracy: 0.5034 - val_loss: 0.6962 - val_accuracy: 0.4453 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.4878\n",
            "Epoch 14: val_loss did not improve from 0.62821\n",
            "33/33 [==============================] - 30s 909ms/step - loss: 0.6932 - accuracy: 0.4878 - val_loss: 0.6969 - val_accuracy: 0.4453 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.4869\n",
            "Epoch 15: val_loss did not improve from 0.62821\n",
            "33/33 [==============================] - 29s 905ms/step - loss: 0.6932 - accuracy: 0.4869 - val_loss: 0.7002 - val_accuracy: 0.4023 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.4869\n",
            "Epoch 16: val_loss did not improve from 0.62821\n",
            "33/33 [==============================] - 29s 870ms/step - loss: 0.6932 - accuracy: 0.4869 - val_loss: 0.7003 - val_accuracy: 0.4062 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.4869\n",
            "Epoch 17: val_loss did not improve from 0.62821\n",
            "33/33 [==============================] - 30s 895ms/step - loss: 0.6932 - accuracy: 0.4869 - val_loss: 0.7003 - val_accuracy: 0.4062 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.4869\n",
            "Epoch 18: val_loss did not improve from 0.62821\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "33/33 [==============================] - 29s 867ms/step - loss: 0.6932 - accuracy: 0.4869 - val_loss: 0.7003 - val_accuracy: 0.4062 - lr: 1.0000e-04\n",
            "Epoch 18: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NZBxGpJVK6Cb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}