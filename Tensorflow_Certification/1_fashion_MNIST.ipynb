{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Raw Cell Format",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Judy-Choi/Tensorflow_Certificate/blob/main/1.fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3KzJyjv3rnA",
        "outputId": "4a15c324-59e4-4c7b-ffd1-0bbd4dc1c296"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        " \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout,BatchNormalization\n",
        "print(tf.__version__)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "# numpy float 출력옵션 변경\n",
        "np.set_printoptions(formatter={'float_kind': lambda x: \"{0:0.3f}\".format(x)})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iYO7SPdwOSb"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_yhs5oCCFF-"
      },
      "source": [
        "## 1. 데이터셋 준비하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmxkHFpt31bM"
      },
      "source": [
        "fmnist = tf.keras.datasets.fashion_mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTdRgExe4TRB",
        "outputId": "0519666b-3475-42bd-b438-f896782a75e3"
      },
      "source": [
        "# 구글에서 fashion_mnist 데이터는 60000 vs 10000개로 이미 잘라서 보내줌. 옵션으로 바꿀 수 없음\n",
        "(x_train, y_train), (x_test, y_test) = fmnist.load_data()\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mXuqbHqaIH2",
        "outputId": "140a3b7b-b95b-4d2c-da9e-ae859895c062"
      },
      "source": [
        "print('length:', len(x_train))\n",
        "print('ndim:', x_train.ndim)\n",
        "print('size:', x_train.size, 60000*28*28)\n",
        "print('dtype:', x_train.dtype)\n",
        "print('dtype.name:', x_train.dtype.name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length: 60000\n",
            "ndim: 3\n",
            "size: 47040000 47040000\n",
            "dtype: uint8\n",
            "dtype.name: uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSV8730_CFGE"
      },
      "source": [
        "## 2.데이터 프리프로세싱"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "FPc9d3gJ3jWF",
        "outputId": "6a4e4c2a-096e-4147-94b2-86f57860a32b"
      },
      "source": [
        "class_names = ['T-shirts/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "print(y_train[1])\n",
        "print(class_names[y_train[1]])\n",
        "plt.imshow(x_train[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "T-shirts/top\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc0e104a3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIerfQoYJo6w",
        "outputId": "b6be27f3-d8d4-441f-a5d2-1fd2b3f628b8"
      },
      "source": [
        "print(x_train[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   1   0   0   0   0  41 188 103  54  48  43  87 168\n",
            "  133  16   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   1   0   0   0  49 136 219 216 228 236 255 255 255 255 217\n",
            "  215 254 231 160  45   0   0   0   0   0]\n",
            " [  0   0   0   0   0  14 176 222 224 212 203 198 196 200 215 204 202 201\n",
            "  201 201 209 218 224 164   0   0   0   0]\n",
            " [  0   0   0   0   0 188 219 200 198 202 198 199 199 201 196 198 198 200\n",
            "  200 200 200 201 200 225  41   0   0   0]\n",
            " [  0   0   0   0  51 219 199 203 203 212 238 248 250 245 249 246 247 252\n",
            "  248 235 207 203 203 222 140   0   0   0]\n",
            " [  0   0   0   0 116 226 206 204 207 204 101  75  47  73  48  50  45  51\n",
            "   63 113 222 202 206 220 224   0   0   0]\n",
            " [  0   0   0   0 200 222 209 203 215 200   0  70  98   0 103  59  68  71\n",
            "   49   0 219 206 214 210 250  38   0   0]\n",
            " [  0   0   0   0 247 218 212 210 215 214   0 254 243 139 255 174 251 255\n",
            "  205   0 215 217 214 208 220  95   0   0]\n",
            " [  0   0   0  45 226 214 214 215 224 205   0  42  35  60  16  17  12  13\n",
            "   70   0 189 216 212 206 212 156   0   0]\n",
            " [  0   0   0 164 235 214 211 220 216 201  52  71  89  94  83  78  70  76\n",
            "   92  87 206 207 222 213 219 208   0   0]\n",
            " [  0   0   0 106 187 223 237 248 211 198 252 250 248 245 248 252 253 250\n",
            "  252 239 201 212 225 215 193 113   0   0]\n",
            " [  0   0   0   0   0  17  54 159 222 193 208 192 197 200 200 200 200 201\n",
            "  203 195 210 165   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  47 225 192 214 203 206 204 204 205 206 204\n",
            "  212 197 218 107   0   0   0   0   0   0]\n",
            " [  0   0   0   0   1   6   0  46 212 195 212 202 206 205 204 205 206 204\n",
            "  212 200 218  91   0   3   1   0   0   0]\n",
            " [  0   0   0   0   0   1   0  11 197 199 205 202 205 206 204 205 207 204\n",
            "  205 205 218  77   0   5   0   0   0   0]\n",
            " [  0   0   0   0   0   3   0   2 191 198 201 205 206 205 205 206 209 206\n",
            "  199 209 219  74   0   5   0   0   0   0]\n",
            " [  0   0   0   0   0   2   0   0 188 197 200 207 207 204 207 207 210 208\n",
            "  198 207 221  72   0   4   0   0   0   0]\n",
            " [  0   0   0   0   0   2   0   0 215 198 203 206 208 205 207 207 210 208\n",
            "  200 202 222  75   0   4   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0 212 198 209 206 209 206 208 207 211 206\n",
            "  205 198 221  80   0   3   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0 204 201 205 208 207 205 211 205 210 210\n",
            "  209 195 221  96   0   3   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0 202 201 205 209 207 205 213 206 210 209\n",
            "  210 194 217 105   0   2   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0 204 204 205 208 207 205 215 207 210 208\n",
            "  211 193 213 115   0   2   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 204 207 207 208 206 206 215 210 210 207\n",
            "  212 195 210 118   0   2   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0 198 208 208 208 204 207 212 212 210 207\n",
            "  211 196 207 121   0   1   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0 198 210 207 208 206 209 213 212 211 207\n",
            "  210 197 207 124   0   1   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 172 210 203 201 199 204 207 205 204 201\n",
            "  205 197 206 127   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 188 221 214 234 236 238 244 244 244 240\n",
            "  243 214 224 162   0   2   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0 139 146 130 135 135 137 125 124 125 121\n",
            "  119 114 130  76   0   0   0   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRH19pWs6ZDn"
      },
      "source": [
        "x_train  = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIn7S9gf62ie"
      },
      "source": [
        "## 4. 모델 설계하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mAyndG3kVlK"
      },
      "source": [
        "# 28*28 = 784   \n",
        "model = Sequential([Flatten(), \n",
        "                    Dense(32, activation='relu'), \n",
        "                    Dense(10, activation='softmax')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLMdl9aP8nQ0"
      },
      "source": [
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aK_Yro40CFGN"
      },
      "source": [
        "## 5. 모델 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnlFDRTNCFGN",
        "outputId": "6b5bf371-c8b9-468a-bb9a-78bc547aa090"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test), verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3559 - accuracy: 0.8718 - val_loss: 0.3975 - val_accuracy: 0.8595\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3407 - accuracy: 0.8773 - val_loss: 0.3907 - val_accuracy: 0.8588\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3272 - accuracy: 0.8812 - val_loss: 0.3889 - val_accuracy: 0.8617\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3181 - accuracy: 0.8852 - val_loss: 0.3694 - val_accuracy: 0.8682\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3082 - accuracy: 0.8873 - val_loss: 0.3755 - val_accuracy: 0.8680\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbfb04af580>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JJMsvSB-1UY"
      },
      "source": [
        "## 7. 모델 검증하기"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IHxj3-Bo_Pdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzlqsEzX9s5P",
        "outputId": "b357f71c-81a6-4daa-fdef-ac681f3f8051"
      },
      "source": [
        "model.summary()\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3755 - accuracy: 0.8680\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3755055367946625, 0.8679999709129333]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyTB2gkNx5kV",
        "outputId": "e68153f5-bf0b-4101-9d11-6f5ee9201247"
      },
      "source": [
        "print(y_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBPb4xv2CFGS"
      },
      "source": [
        "## 8. 모델 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyEIki0z_hAD",
        "outputId": "8f58ff56-3773-496f-cde9-a0c419a78fe3"
      },
      "source": [
        "pred_test = model.predict(x_test)\n",
        "print(pred_test[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 1ms/step\n",
            "[0.000 0.000 0.000 0.000 0.000 0.007 0.000 0.018 0.000 0.974]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdzqbQhRArzm"
      },
      "source": [
        "y_test[0]는 무엇을 한다는 뜻일까?  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "WmP5H7jkQjBN",
        "outputId": "40de5a51-5ee3-48db-cd3f-207c59a255c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbfb0294dc0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQQUlEQVR4nO3dW4xd9XXH8d+amTMXxjb24EtdY7ANBuFWwrRTkzaoIiJJCS8mUovgIaUSkiMVpCAhtYg+BPWJNk2jPlSRnAbFrVJQqgSBKtRALRoaJUKYS4yBhotlGhvbgxlfxte5rT7MBg0we+3h3NP1/UijObPX7H2Wz5yf9znnv/f+m7sLwP9/PZ1uAEB7EHYgCcIOJEHYgSQIO5BEXzvvrN8GfFDD7bxLIJXzOqNJv2AL1RoKu5ndLOkfJPVK+id3fyj6/UEN63q7qZG7BBB4zneX1up+GW9mvZL+UdKXJG2RdIeZbal3ewBaq5H37NskveXu+919UtKjkrY3py0AzdZI2NdJ+tW8nw8Wyz7CzHaY2R4z2zOlCw3cHYBGtPzTeHff6e6j7j5a00Cr7w5AiUbCfkjS+nk/X1osA9CFGgn785I2m9lGM+uXdLukJ5rTFoBmq3vozd2nzeweST/W3NDbw+7+atM6A9BUDY2zu/uTkp5sUi8AWojDZYEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJNDRls5kdkDQhaUbStLuPNqMpAM3XUNgLn3P3Y03YDoAW4mU8kESjYXdJT5nZC2a2Y6FfMLMdZrbHzPZM6UKDdwegXo2+jL/B3Q+Z2WpJT5vZ/7j7s/N/wd13StopSctsxBu8PwB1amjP7u6Hiu9jkh6TtK0ZTQFovrrDbmbDZrb0g9uSvihpX7MaA9BcjbyMXyPpMTP7YDv/6u7/0ZSuADRd3WF39/2Srm1iLwBaiKE3IAnCDiRB2IEkCDuQBGEHkmjGiTBAR1hf/PT1mZmg2NjBnD0XXRTWZ8+eDet23W+V1vylV+vqqQp7diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH27OZOUQ7qFfuD2WAsW1Lv5k2ltbEb14Trrv6318L6zImTYb2VqsbRq+y/bVlpbeNLDW26FHt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcXbEKsbRqxz5fPlY+vHRqXDdM2vLz/mWpMv++md19dQMfZevD+uHtsf12kQzu1kc9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7MlZXy2s+9RkWJ/6/O+G9ZNXl1+fvfZefN8Xrjgf15/aENaPnFhaWrtoMP53HT94cVivrbgQ1i9eeiysn3w33n4rVO7ZzexhMxszs33zlo2Y2dNm9mbxfUVr2wTQqMW8jP+epJs/tux+SbvdfbOk3cXPALpYZdjd/VlJ4x9bvF3SruL2Lkm3NrctAM1W73v2Ne5+uLh9RFLpAdBmtkPSDkkaVDw/FoDWafjTeHd3SaWfwrj7TncfdffRmgYavTsAdao37EfNbK0kFd/HmtcSgFaoN+xPSLqzuH2npMeb0w6AVql8z25mj0i6UdJKMzso6euSHpL0AzO7S9I7km5rZZNoQE9vWK4aR+9dHo8Hv/HH8fYtGI6eGYjnSB9aEo9lm8Xr9/SU16vWvfLqw2F9/7srw/rxk8NhXX2NzQ9fj8qwu/sdJaWbmtwLgBbicFkgCcIOJEHYgSQIO5AEYQeS4BTXxYqmNvaKYZSK4S/5bEU93r71lf8ZfXo63naFt+/bEtYHKg6n6j1f/ridvSzu7aKB+FLTB9+LT7bs6S1/XGdn4/3c+NmhsD47Gf9NB5bGw4a1/vJ/e9VwZ71TVbNnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk8oyzR+PkUvVYeVU90uC0x9E4utTYWPrYn/9BWJ9cHY91L98bXw56Nmi9b1l8eu348fg0UT/eH9cvKd9+rS/+m9R6G/ubRafXStKSofJx+KlrN8Xb/slL9fVU11oAfu0QdiAJwg4kQdiBJAg7kARhB5Ig7EASecbZGxknl8Jz0q234nLN0/FYdVVvjYyjH74vHkefuDLe9uChimmVR+L79+DwhsGheJz99OEl8caXxGPh0WUCTp+LZycaGoh7U+VhGxW/EHjn5sGwvvEn9W2XPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJPHrNc5edf31SNW12a3i/73gnHRv8Hz1Kr1XbgzrB25fW1qbGao4r/rt+CkwXTHzcNW0y5Mj5Y9N/2R831YxVt03VHH8QmBmJv57n5+Mjy/QTNzbhbMV5/nPlq9/+baD8X3XqXLPbmYPm9mYme2bt+xBMztkZi8XX7e0pDsATbOYl/Hfk3TzAsu/5e5bi68nm9sWgGarDLu7PytpvA29AGihRj6gu8fM9hYv80sn3TKzHWa2x8z2TCme/wpA69Qb9m9LukLSVkmHJX2z7Bfdfae7j7r7aE3xyQcAWqeusLv7UXefcfdZSd+RtK25bQFotrrCbmbzx3q+LGlf2e8C6A6V4+xm9oikGyWtNLODkr4u6UYz2yrJJR2Q9NVF3Zs1OJd4K8ezvf5t962/NKyfu3pNWB+/Jn57c+434rHsnuDU69pEPB48eXG87emlFefa1yquE9BffnyDB2PNknTxpfE85AO1+PkyfrL8IIGZ6YprEFT0porrwvu5iuMXesvXP3Y6Prhh1e9fW178xc9KS5Vhd/c7Flj83ar1AHQXDpcFkiDsQBKEHUiCsANJEHYgifae4uqNXRa5b8NlpbVzV60O151aEg+1TA7H/+9ND5XXJjaEq1aeZtozFdf7zsTDQB60Prks3vbMYFy3qtHQofjUYTtX/rhPTcaP+WR/fOcnji4N67Vl5YdnV13G+syJ4A8uqTYcr79q+emwfvJs+favWXk0XPfg6s2ltdla+XOFPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJNFVl5I+/SfXx/XfLB+z7akYDz6/Mq57cMqhJFlw6eCe6Yp1T8fj5NPD8frn11ScfhttPjjFVJJ6T8RPgWgMX5J6l8QPfE9P+f1PVVxu+dyZ+NTf3lPxsRMDq+o/pqPK1Il4WuWx2fiBi8b5l/efC9d9Nzguw4KnEnt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiirePssyuGNfFHnymtT//p++H6p9+8pLQ2eDT+f6sWn14s74nHwqPLNXtvxWWHK8q1inH42Vr8b7NgKH2q4lLQVb1Vne9eORN2X/n6I6tPhetec8lYvPEr4/Ky2vnSWp9VHLuwPi4fOb8srK8eiJ9w45MXldbePXtxuO7Qu2dKaz2T5X8Q9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kERbx9l7Jy5o+X/tL62/sW1TuP7qLe+V1i7/veN19yVJ56fjc6uPnl1SWjt2PL5++fSJ/rBeqzgve7ZiWmQPxsp9ZCpcd+um/w3rqwbj8eJNQ8fC+kxwQvwDK38Zrvs375dfH12Snjp6TVj/xlX/Xlob6Y3PlZ/xiuMTKpz1+HH/8dnyORDeOh9P8f3fy9eV1ryv/PGu3LOb2Xoze8bMXjOzV83sa8XyETN72szeLL6vqNoWgM5ZzMv4aUn3ufsWSZ+RdLeZbZF0v6Td7r5Z0u7iZwBdqjLs7n7Y3V8sbk9Iel3SOknbJe0qfm2XpFtb1COAJvhU79nNbIOk6yQ9J2mNux8uSkckLfhGw8x2SNohSYM95e97AbTWoj+NN7Mlkn4o6V53/8gZDO7ukhb8RMPdd7r7qLuP9vfEk+UBaJ1Fhd3MapoL+vfd/UfF4qNmtraor5VUcYoSgE4yrxhiMDPT3HvycXe/d97yb0h6390fMrP7JY24+19E21pmI3693dR41wvoXREPBpy66aqwfvyqePirb1v50N4VI/Hw02XD8bDguoG43rvwi6YPzQTnqU7Nxu/UXju9Nqz/fP/GsL7imfiSyqse3Vtamz1TfqpmM8zuLj9P9XOr3gjX3TtRPrwlSUfOxKe4vn+m/BRWSZqejqayjv9mV91dPnz981OP6+T0ews+IRbznv2zkr4i6RUze7lY9oCkhyT9wMzukvSOpNsWsS0AHVIZdnf/qcovcdCa3TSApuNwWSAJwg4kQdiBJAg7kARhB5KoHGdvplaOswOQnvPdOuXjC46esWcHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkKsNuZuvN7Bkze83MXjWzrxXLHzSzQ2b2cvF1S+vbBVCvxczPPi3pPnd/0cyWSnrBzJ4uat9y979rXXsAmmUx87MflnS4uD1hZq9LWtfqxgA016d6z25mGyRdJ+m5YtE9ZrbXzB42sxUl6+wwsz1mtmdKFxrrFkDdFh12M1si6YeS7nX3U5K+LekKSVs1t+f/5kLruftOdx9199GaBhrvGEBdFhV2M6tpLujfd/cfSZK7H3X3GXeflfQdSdta1yaARi3m03iT9F1Jr7v7389bvnber31Z0r7mtwegWRbzafxnJX1F0itm9nKx7AFJd5jZVkku6YCkr7agPwBNsphP438qaaH5np9sfjsAWoUj6IAkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0mYu7fvzszek/TOvEUrJR1rWwOfTrf21q19SfRWr2b2drm7r1qo0Nawf+LOzfa4+2jHGgh0a2/d2pdEb/VqV2+8jAeSIOxAEp0O+84O33+kW3vr1r4keqtXW3rr6Ht2AO3T6T07gDYh7EASHQm7md1sZr80s7fM7P5O9FDGzA6Y2SvFNNR7OtzLw2Y2Zmb75i0bMbOnzezN4vuCc+x1qLeumMY7mGa8o49dp6c/b/t7djPrlfSGpC9IOijpeUl3uPtrbW2khJkdkDTq7h0/AMPM/lDSaUn/7O6/XSz7W0nj7v5Q8R/lCnf/yy7p7UFJpzs9jXcxW9Ha+dOMS7pV0p+pg49d0NdtasPj1ok9+zZJb7n7fneflPSopO0d6KPrufuzksY/tni7pF3F7V2ae7K0XUlvXcHdD7v7i8XtCUkfTDPe0ccu6KstOhH2dZJ+Ne/ng+qu+d5d0lNm9oKZ7eh0MwtY4+6Hi9tHJK3pZDMLqJzGu50+Ns141zx29Ux/3ig+oPukG9z9dyR9SdLdxcvVruRz78G6aex0UdN4t8sC04x/qJOPXb3TnzeqE2E/JGn9vJ8vLZZ1BXc/VHwfk/SYum8q6qMfzKBbfB/rcD8f6qZpvBeaZlxd8Nh1cvrzToT9eUmbzWyjmfVLul3SEx3o4xPMbLj44ERmNizpi+q+qaifkHRncftOSY93sJeP6JZpvMumGVeHH7uOT3/u7m3/knSL5j6Rf1vSX3Wih5K+Nkn6RfH1aqd7k/SI5l7WTWnus427JF0iabekNyX9p6SRLurtXyS9Immv5oK1tkO93aC5l+h7Jb1cfN3S6ccu6KstjxuHywJJ8AEdkARhB5Ig7EAShB1IgrADSRB2IAnCDiTxfzz9+3wjTHA+AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnBGOrMiA1n5",
        "outputId": "c1b3b15a-8ee6-4365-b092-81e83fdf6cb1"
      },
      "source": [
        "print(y_test[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgQSIfDSOWv6"
      },
      "source": [
        "## Dense Layer 에서 neuron의 수를 올리면  accuracy는 어떻게 될까요 ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGBx5wJtCFGX"
      },
      "source": [
        "### training time은 어떻게 될까요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSZSwV5UObQP",
        "outputId": "269a82ef-c055-484d-8c55-1f8d5930e9ac"
      },
      "source": [
        "import tensorflow as tf\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_train, y_train) ,  (x_test, y_test) = fmnist.load_data()\n",
        "\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0\n",
        "\n",
        "model = Sequential([Flatten(),                 \n",
        "                    Dense(1024, activation=\"relu\"),\n",
        "                    Dense(256, activation=\"relu\"),\n",
        "                    Dense(256, activation=\"relu\"),\n",
        "                    Dense(256, activation=\"relu\"),\n",
        "                    Dense(64, activation=\"relu\"),\n",
        "                    Dense(32, activation=\"relu\"),\n",
        "                    Dense(10, activation=\"softmax\")])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "            loss = 'sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(x_train, y_train,  validation_data=(x_test, y_test), epochs=5)\n",
        "model.summary()\n",
        "print('***evaluate model')\n",
        "model.evaluate(x_test, y_test)\n",
        "print('*** real test ***')\n",
        "pred_test = model.predict(x_test)\n",
        "\n",
        "print(pred_test[0])\n",
        "print(y_test[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 11s 4ms/step - loss: 0.5244 - accuracy: 0.8100 - val_loss: 0.4385 - val_accuracy: 0.8405\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3881 - accuracy: 0.8607 - val_loss: 0.4016 - val_accuracy: 0.8567\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3486 - accuracy: 0.8741 - val_loss: 0.3875 - val_accuracy: 0.8602\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3227 - accuracy: 0.8833 - val_loss: 0.3681 - val_accuracy: 0.8698\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3049 - accuracy: 0.8892 - val_loss: 0.3524 - val_accuracy: 0.8741\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1024)              803840    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               262400    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,216,682\n",
            "Trainable params: 1,216,682\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "***evaluate model\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3524 - accuracy: 0.8741\n",
            "*** real test ***\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.064 0.001 0.934]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqoCR-ieSGDg"
      },
      "source": [
        "## 만일 마지막 Dense layer에서 output neuron의 숫자를 5로 바꾸면? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh0NOtWxCFGa"
      },
      "source": [
        "### label의 종류가 10개인데... output은 5개라...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMckVntcSPvo",
        "outputId": "1ba36904-ab44-48f3-d687-8ad60a7c7a71"
      },
      "source": [
        "import tensorflow as tf\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "(x_train, y_train) ,  (x_test, y_test) = fmnist.load_data()\n",
        "\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0\n",
        "\n",
        "model = Sequential([Flatten(),\n",
        "              Dense(32, activation=\"relu\"),\n",
        "              Dense(5, activation=\"softmax\")])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,  validation_data=(x_test, y_test),epochs=5)\n",
        "model.summary()\n",
        "print('***evaluate model')\n",
        "model.evaluate(x_test, y_test)\n",
        "print('*** real test ***')\n",
        "pred_test = model.predict(x_test)\n",
        "\n",
        "print(pred_test[0])\n",
        "print(y_test[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,285\n",
            "Trainable params: 25,285\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "***evaluate model\n",
            "313/313 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.1000\n",
            "*** real test ***\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[nan nan nan nan nan]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0lF5MuvSuZF"
      },
      "source": [
        "## 그러면 Dense Layer를 하나 더 쌓으면 어떻게 될까요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1YPa6UhS8Es",
        "outputId": "9fbd5841-34dc-44c8-85ee-b39b40a78bc2"
      },
      "source": [
        "import tensorflow as tf\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_train, y_train) ,  (x_test, y_test) = fmnist.load_data()\n",
        "\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0\n",
        "\n",
        "model = Sequential([Flatten(),\n",
        "                    Dense(32, activation=\"relu\"),\n",
        "                    Dense(32, activation=\"relu\"),\n",
        "                    Dense(10, activation=\"softmax\")])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "            loss = 'sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5)\n",
        "model.summary()\n",
        "print('***evaluate model')\n",
        "model.evaluate(x_test, y_test)\n",
        "print('*** real test ***')\n",
        "pred_test = model.predict(x_test)\n",
        "\n",
        "print(pred_test[0])\n",
        "print(y_test[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5668 - accuracy: 0.8041 - val_loss: 0.4605 - val_accuracy: 0.8408\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4160 - accuracy: 0.8524 - val_loss: 0.4322 - val_accuracy: 0.8424\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3833 - accuracy: 0.8629 - val_loss: 0.4215 - val_accuracy: 0.8472\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3597 - accuracy: 0.8698 - val_loss: 0.3933 - val_accuracy: 0.8593\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3440 - accuracy: 0.8755 - val_loss: 0.3851 - val_accuracy: 0.8617\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,506\n",
            "Trainable params: 26,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "***evaluate model\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3851 - accuracy: 0.8617\n",
            "*** real test ***\n",
            "[0.000 0.000 0.000 0.000 0.000 0.013 0.000 0.057 0.000 0.931]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bql9fyaNUSFy"
      },
      "source": [
        "## epochs 의 숫자를 올리면 어떻게 될까요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE3esj9BURQe",
        "outputId": "1d821dd5-f322-4b4a-f741-23fb6ba67c1d"
      },
      "source": [
        "import tensorflow as tf\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_train, y_train) ,  (x_test, y_test) = fmnist.load_data()\n",
        "\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0\n",
        "\n",
        "model = Sequential([Flatten(),\n",
        "              Dense(32, activation=\"relu\"),\n",
        "              Dense(10, activation=\"softmax\")])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=30)\n",
        "model.summary()\n",
        "print('***evaluate model')\n",
        "model.evaluate(x_test, y_test)\n",
        "print('*** real test ***')\n",
        "pred_test = model.predict(x_test)\n",
        "\n",
        "print(pred_test[0])\n",
        "print(y_test[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5491 - accuracy: 0.8100 - val_loss: 0.4698 - val_accuracy: 0.8341\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4170 - accuracy: 0.8526 - val_loss: 0.4301 - val_accuracy: 0.8451\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3838 - accuracy: 0.8624 - val_loss: 0.4109 - val_accuracy: 0.8529\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3607 - accuracy: 0.8720 - val_loss: 0.4087 - val_accuracy: 0.8526\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3434 - accuracy: 0.8759 - val_loss: 0.3993 - val_accuracy: 0.8566\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3320 - accuracy: 0.8806 - val_loss: 0.3837 - val_accuracy: 0.8623\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3211 - accuracy: 0.8818 - val_loss: 0.3624 - val_accuracy: 0.8700\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3095 - accuracy: 0.8878 - val_loss: 0.3795 - val_accuracy: 0.8654\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3046 - accuracy: 0.8881 - val_loss: 0.3683 - val_accuracy: 0.8642\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2977 - accuracy: 0.8904 - val_loss: 0.3796 - val_accuracy: 0.8623\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2911 - accuracy: 0.8934 - val_loss: 0.3559 - val_accuracy: 0.8702\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2858 - accuracy: 0.8956 - val_loss: 0.3856 - val_accuracy: 0.8603\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2807 - accuracy: 0.8973 - val_loss: 0.3790 - val_accuracy: 0.8647\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2767 - accuracy: 0.8983 - val_loss: 0.3771 - val_accuracy: 0.8648\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2707 - accuracy: 0.8999 - val_loss: 0.3687 - val_accuracy: 0.8693\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2684 - accuracy: 0.9001 - val_loss: 0.3553 - val_accuracy: 0.8737\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2622 - accuracy: 0.9041 - val_loss: 0.3727 - val_accuracy: 0.8688\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2598 - accuracy: 0.9043 - val_loss: 0.3605 - val_accuracy: 0.8745\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2566 - accuracy: 0.9051 - val_loss: 0.3642 - val_accuracy: 0.8711\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2528 - accuracy: 0.9054 - val_loss: 0.3707 - val_accuracy: 0.8707\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2502 - accuracy: 0.9077 - val_loss: 0.3698 - val_accuracy: 0.8721\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2464 - accuracy: 0.9088 - val_loss: 0.3678 - val_accuracy: 0.8723\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2448 - accuracy: 0.9090 - val_loss: 0.3615 - val_accuracy: 0.8761\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2406 - accuracy: 0.9119 - val_loss: 0.3764 - val_accuracy: 0.8722\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2393 - accuracy: 0.9121 - val_loss: 0.3601 - val_accuracy: 0.8727\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2375 - accuracy: 0.9117 - val_loss: 0.3662 - val_accuracy: 0.8729\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2343 - accuracy: 0.9143 - val_loss: 0.3855 - val_accuracy: 0.8696\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2330 - accuracy: 0.9127 - val_loss: 0.3940 - val_accuracy: 0.8645\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2298 - accuracy: 0.9143 - val_loss: 0.3817 - val_accuracy: 0.8718\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2294 - accuracy: 0.9148 - val_loss: 0.3784 - val_accuracy: 0.8719\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "***evaluate model\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3784 - accuracy: 0.8719\n",
            "*** real test ***\n",
            "313/313 [==============================] - 0s 1ms/step\n",
            "[0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.008 0.000 0.992]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS3vVkOgCDGZ"
      },
      "source": [
        "## 만일 데이터를 normalize를 안한다면 어떻게 될까요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDqNAqrpCNg0",
        "outputId": "4479394d-0d68-4b33-ebdf-2fdfd0664024"
      },
      "source": [
        "import tensorflow as tf\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "(x_train, y_train) ,  (x_test, y_test) = fmnist.load_data()\n",
        "\n",
        "#x_train = x_train/255.0\n",
        "#x_test = x_test/255.0\n",
        "\n",
        "model = Sequential([Flatten(),\n",
        "              Dense(32, activation=\"relu\"),\n",
        "              Dense(10, activation=\"softmax\")])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5)\n",
        "model.summary()\n",
        "print('***evaluate model')\n",
        "model.evaluate(x_test, y_test)\n",
        "print('*** real test ***')\n",
        "pred_test = model.predict(x_test)\n",
        "\n",
        "print(pred_test[0])\n",
        "print(y_test[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 2.3546 - accuracy: 0.3555 - val_loss: 1.4643 - val_accuracy: 0.4919\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.2349 - accuracy: 0.5410 - val_loss: 1.0822 - val_accuracy: 0.5889\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9829 - accuracy: 0.6308 - val_loss: 0.9908 - val_accuracy: 0.6711\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.8365 - accuracy: 0.6787 - val_loss: 0.8909 - val_accuracy: 0.6878\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.7099 - accuracy: 0.7362 - val_loss: 0.7157 - val_accuracy: 0.7363\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_4 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "***evaluate model\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7157 - accuracy: 0.7363\n",
            "*** real test ***\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[0.000 0.000 0.000 0.000 0.000 0.255 0.000 0.064 0.000 0.682]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7W2PT66ZBHQ"
      },
      "source": [
        "## callback function을 써봅시다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkaEHHgqZbYv",
        "outputId": "f1855635-a872-44d9-a271-07bd81ac6c8c"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('val_accuracy') > 0.95):\n",
        "            print(\"\\nReached 95% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "tcallbacks = [TensorBoard('./tboard')]\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
        "checkpoint_path = 'checkpoint.ckpt'\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, \n",
        "        save_best_only=True, \n",
        "        save_weights_only=True, \n",
        "        monitor='val_loss', \n",
        "        verbose=1)\n",
        "\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_train, y_train) ,  (x_test, y_test) = fmnist.load_data()\n",
        "\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0\n",
        "\n",
        "model = Sequential([Flatten(),\n",
        "              Dense(1024, activation=\"relu\"),\n",
        "              Dropout(0.5),\n",
        "              Dense(256, activation=\"relu\"),\n",
        "              Dropout(0.5),\n",
        "              Dense(256, activation=\"relu\"),\n",
        "              BatchNormalization(),\n",
        "              Dense(64, activation=\"relu\"),\n",
        "              BatchNormalization(),\n",
        "              Dense(10, activation=\"softmax\")])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), \n",
        "                    epochs=100, \n",
        "                    callbacks=[tcallbacks, callbacks,checkpoint, early_stopping])\n",
        "model.load_weights(checkpoint_path)\n",
        "\n",
        "model.save(\"fashion-mnist.h5\")      \n",
        "\n",
        "print(pred_test[0])\n",
        "print(y_test[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "   1/1875 [..............................] - ETA: 40:01 - loss: 3.3625 - accuracy: 0.0312WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_train_batch_end` time: 0.0045s). Check your callbacks.\n",
            "1866/1875 [============================>.] - ETA: 0s - loss: 0.6995 - accuracy: 0.7446\n",
            "Epoch 1: val_loss improved from inf to 0.49719, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.6982 - accuracy: 0.7452 - val_loss: 0.4972 - val_accuracy: 0.8208\n",
            "Epoch 2/100\n",
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.4966 - accuracy: 0.8216\n",
            "Epoch 2: val_loss improved from 0.49719 to 0.45514, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4968 - accuracy: 0.8215 - val_loss: 0.4551 - val_accuracy: 0.8339\n",
            "Epoch 3/100\n",
            "1866/1875 [============================>.] - ETA: 0s - loss: 0.4515 - accuracy: 0.8391\n",
            "Epoch 3: val_loss improved from 0.45514 to 0.39475, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4512 - accuracy: 0.8392 - val_loss: 0.3948 - val_accuracy: 0.8544\n",
            "Epoch 4/100\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.4231 - accuracy: 0.8474\n",
            "Epoch 4: val_loss improved from 0.39475 to 0.39346, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4231 - accuracy: 0.8474 - val_loss: 0.3935 - val_accuracy: 0.8538\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.4071 - accuracy: 0.8524\n",
            "Epoch 5: val_loss improved from 0.39346 to 0.37550, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4071 - accuracy: 0.8524 - val_loss: 0.3755 - val_accuracy: 0.8619\n",
            "Epoch 6/100\n",
            "1864/1875 [============================>.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8605\n",
            "Epoch 6: val_loss improved from 0.37550 to 0.36632, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3875 - accuracy: 0.8605 - val_loss: 0.3663 - val_accuracy: 0.8666\n",
            "Epoch 7/100\n",
            "1863/1875 [============================>.] - ETA: 0s - loss: 0.3772 - accuracy: 0.8643\n",
            "Epoch 7: val_loss improved from 0.36632 to 0.36166, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3769 - accuracy: 0.8644 - val_loss: 0.3617 - val_accuracy: 0.8708\n",
            "Epoch 8/100\n",
            "1862/1875 [============================>.] - ETA: 0s - loss: 0.3667 - accuracy: 0.8676\n",
            "Epoch 8: val_loss improved from 0.36166 to 0.35543, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3672 - accuracy: 0.8673 - val_loss: 0.3554 - val_accuracy: 0.8706\n",
            "Epoch 9/100\n",
            "1869/1875 [============================>.] - ETA: 0s - loss: 0.3578 - accuracy: 0.8697\n",
            "Epoch 9: val_loss improved from 0.35543 to 0.35114, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3582 - accuracy: 0.8697 - val_loss: 0.3511 - val_accuracy: 0.8731\n",
            "Epoch 10/100\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.3480 - accuracy: 0.8733\n",
            "Epoch 10: val_loss improved from 0.35114 to 0.34121, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3479 - accuracy: 0.8733 - val_loss: 0.3412 - val_accuracy: 0.8784\n",
            "Epoch 11/100\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.3402 - accuracy: 0.8763\n",
            "Epoch 11: val_loss improved from 0.34121 to 0.33588, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3402 - accuracy: 0.8763 - val_loss: 0.3359 - val_accuracy: 0.8783\n",
            "Epoch 12/100\n",
            "1869/1875 [============================>.] - ETA: 0s - loss: 0.3333 - accuracy: 0.8811\n",
            "Epoch 12: val_loss did not improve from 0.33588\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3331 - accuracy: 0.8811 - val_loss: 0.3360 - val_accuracy: 0.8770\n",
            "Epoch 13/100\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.3279 - accuracy: 0.8794\n",
            "Epoch 13: val_loss improved from 0.33588 to 0.33163, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3279 - accuracy: 0.8794 - val_loss: 0.3316 - val_accuracy: 0.8784\n",
            "Epoch 14/100\n",
            "1869/1875 [============================>.] - ETA: 0s - loss: 0.3219 - accuracy: 0.8826\n",
            "Epoch 14: val_loss did not improve from 0.33163\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3216 - accuracy: 0.8827 - val_loss: 0.3349 - val_accuracy: 0.8806\n",
            "Epoch 15/100\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.3194 - accuracy: 0.8852\n",
            "Epoch 15: val_loss improved from 0.33163 to 0.32999, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3196 - accuracy: 0.8852 - val_loss: 0.3300 - val_accuracy: 0.8799\n",
            "Epoch 16/100\n",
            "1861/1875 [============================>.] - ETA: 0s - loss: 0.3142 - accuracy: 0.8861\n",
            "Epoch 16: val_loss did not improve from 0.32999\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3140 - accuracy: 0.8862 - val_loss: 0.3330 - val_accuracy: 0.8816\n",
            "Epoch 17/100\n",
            "1864/1875 [============================>.] - ETA: 0s - loss: 0.3070 - accuracy: 0.8881\n",
            "Epoch 17: val_loss improved from 0.32999 to 0.32376, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3072 - accuracy: 0.8881 - val_loss: 0.3238 - val_accuracy: 0.8865\n",
            "Epoch 18/100\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.3030 - accuracy: 0.8889\n",
            "Epoch 18: val_loss did not improve from 0.32376\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3030 - accuracy: 0.8890 - val_loss: 0.3329 - val_accuracy: 0.8798\n",
            "Epoch 19/100\n",
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.2979 - accuracy: 0.8913\n",
            "Epoch 19: val_loss improved from 0.32376 to 0.31871, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2979 - accuracy: 0.8913 - val_loss: 0.3187 - val_accuracy: 0.8863\n",
            "Epoch 20/100\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.2973 - accuracy: 0.8902\n",
            "Epoch 20: val_loss did not improve from 0.31871\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2973 - accuracy: 0.8902 - val_loss: 0.3197 - val_accuracy: 0.8842\n",
            "Epoch 21/100\n",
            "1862/1875 [============================>.] - ETA: 0s - loss: 0.2928 - accuracy: 0.8920\n",
            "Epoch 21: val_loss improved from 0.31871 to 0.31868, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2926 - accuracy: 0.8921 - val_loss: 0.3187 - val_accuracy: 0.8865\n",
            "Epoch 22/100\n",
            "1869/1875 [============================>.] - ETA: 0s - loss: 0.2882 - accuracy: 0.8945\n",
            "Epoch 22: val_loss improved from 0.31868 to 0.31852, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2882 - accuracy: 0.8946 - val_loss: 0.3185 - val_accuracy: 0.8833\n",
            "Epoch 23/100\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.2859 - accuracy: 0.8948\n",
            "Epoch 23: val_loss improved from 0.31852 to 0.31086, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2860 - accuracy: 0.8947 - val_loss: 0.3109 - val_accuracy: 0.8857\n",
            "Epoch 24/100\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.2815 - accuracy: 0.8968\n",
            "Epoch 24: val_loss improved from 0.31086 to 0.30658, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2813 - accuracy: 0.8968 - val_loss: 0.3066 - val_accuracy: 0.8904\n",
            "Epoch 25/100\n",
            "1872/1875 [============================>.] - ETA: 0s - loss: 0.2813 - accuracy: 0.8979\n",
            "Epoch 25: val_loss did not improve from 0.30658\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2813 - accuracy: 0.8979 - val_loss: 0.3096 - val_accuracy: 0.8894\n",
            "Epoch 26/100\n",
            "1860/1875 [============================>.] - ETA: 0s - loss: 0.2795 - accuracy: 0.8970\n",
            "Epoch 26: val_loss did not improve from 0.30658\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2792 - accuracy: 0.8971 - val_loss: 0.3074 - val_accuracy: 0.8900\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.2733 - accuracy: 0.8998\n",
            "Epoch 27: val_loss improved from 0.30658 to 0.30618, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2733 - accuracy: 0.8998 - val_loss: 0.3062 - val_accuracy: 0.8900\n",
            "Epoch 28/100\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.2727 - accuracy: 0.8997\n",
            "Epoch 28: val_loss improved from 0.30618 to 0.30156, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2727 - accuracy: 0.8998 - val_loss: 0.3016 - val_accuracy: 0.8899\n",
            "Epoch 29/100\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.2692 - accuracy: 0.9017\n",
            "Epoch 29: val_loss did not improve from 0.30156\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2694 - accuracy: 0.9017 - val_loss: 0.3183 - val_accuracy: 0.8871\n",
            "Epoch 30/100\n",
            "1862/1875 [============================>.] - ETA: 0s - loss: 0.2662 - accuracy: 0.9031\n",
            "Epoch 30: val_loss did not improve from 0.30156\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2666 - accuracy: 0.9030 - val_loss: 0.3048 - val_accuracy: 0.8896\n",
            "Epoch 31/100\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.2656 - accuracy: 0.9022\n",
            "Epoch 31: val_loss did not improve from 0.30156\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2655 - accuracy: 0.9022 - val_loss: 0.3047 - val_accuracy: 0.8918\n",
            "Epoch 32/100\n",
            "1864/1875 [============================>.] - ETA: 0s - loss: 0.2625 - accuracy: 0.9029\n",
            "Epoch 32: val_loss did not improve from 0.30156\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2624 - accuracy: 0.9030 - val_loss: 0.3060 - val_accuracy: 0.8910\n",
            "Epoch 33/100\n",
            "1869/1875 [============================>.] - ETA: 0s - loss: 0.2615 - accuracy: 0.9050\n",
            "Epoch 33: val_loss improved from 0.30156 to 0.30078, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2615 - accuracy: 0.9051 - val_loss: 0.3008 - val_accuracy: 0.8936\n",
            "Epoch 34/100\n",
            "1864/1875 [============================>.] - ETA: 0s - loss: 0.2592 - accuracy: 0.9041\n",
            "Epoch 34: val_loss did not improve from 0.30078\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2591 - accuracy: 0.9041 - val_loss: 0.3049 - val_accuracy: 0.8897\n",
            "Epoch 35/100\n",
            "1861/1875 [============================>.] - ETA: 0s - loss: 0.2550 - accuracy: 0.9060\n",
            "Epoch 35: val_loss did not improve from 0.30078\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2549 - accuracy: 0.9060 - val_loss: 0.3057 - val_accuracy: 0.8958\n",
            "Epoch 36/100\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.2514 - accuracy: 0.9068\n",
            "Epoch 36: val_loss did not improve from 0.30078\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2516 - accuracy: 0.9067 - val_loss: 0.3111 - val_accuracy: 0.8899\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.2516 - accuracy: 0.9071\n",
            "Epoch 37: val_loss did not improve from 0.30078\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2516 - accuracy: 0.9071 - val_loss: 0.3031 - val_accuracy: 0.8909\n",
            "Epoch 38/100\n",
            "1861/1875 [============================>.] - ETA: 0s - loss: 0.2467 - accuracy: 0.9096\n",
            "Epoch 38: val_loss improved from 0.30078 to 0.29954, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2464 - accuracy: 0.9097 - val_loss: 0.2995 - val_accuracy: 0.8958\n",
            "Epoch 39/100\n",
            "1869/1875 [============================>.] - ETA: 0s - loss: 0.2483 - accuracy: 0.9094\n",
            "Epoch 39: val_loss did not improve from 0.29954\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2481 - accuracy: 0.9095 - val_loss: 0.3040 - val_accuracy: 0.8934\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.2469 - accuracy: 0.9082\n",
            "Epoch 40: val_loss improved from 0.29954 to 0.29474, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2469 - accuracy: 0.9082 - val_loss: 0.2947 - val_accuracy: 0.8950\n",
            "Epoch 41/100\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.2432 - accuracy: 0.9104\n",
            "Epoch 41: val_loss did not improve from 0.29474\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2431 - accuracy: 0.9104 - val_loss: 0.2979 - val_accuracy: 0.8964\n",
            "Epoch 42/100\n",
            "1872/1875 [============================>.] - ETA: 0s - loss: 0.2412 - accuracy: 0.9122\n",
            "Epoch 42: val_loss improved from 0.29474 to 0.29466, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2413 - accuracy: 0.9122 - val_loss: 0.2947 - val_accuracy: 0.8957\n",
            "Epoch 43/100\n",
            "1872/1875 [============================>.] - ETA: 0s - loss: 0.2392 - accuracy: 0.9129\n",
            "Epoch 43: val_loss did not improve from 0.29466\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2392 - accuracy: 0.9129 - val_loss: 0.3033 - val_accuracy: 0.8936\n",
            "Epoch 44/100\n",
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.2362 - accuracy: 0.9140\n",
            "Epoch 44: val_loss did not improve from 0.29466\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2362 - accuracy: 0.9140 - val_loss: 0.2992 - val_accuracy: 0.8933\n",
            "Epoch 45/100\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.2334 - accuracy: 0.9137\n",
            "Epoch 45: val_loss did not improve from 0.29466\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2337 - accuracy: 0.9136 - val_loss: 0.3018 - val_accuracy: 0.8945\n",
            "Epoch 46/100\n",
            "1865/1875 [============================>.] - ETA: 0s - loss: 0.2351 - accuracy: 0.9137\n",
            "Epoch 46: val_loss did not improve from 0.29466\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2350 - accuracy: 0.9137 - val_loss: 0.2961 - val_accuracy: 0.8970\n",
            "Epoch 47/100\n",
            "1860/1875 [============================>.] - ETA: 0s - loss: 0.2325 - accuracy: 0.9142\n",
            "Epoch 47: val_loss improved from 0.29466 to 0.29422, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2322 - accuracy: 0.9143 - val_loss: 0.2942 - val_accuracy: 0.8973\n",
            "Epoch 48/100\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.2323 - accuracy: 0.9146\n",
            "Epoch 48: val_loss did not improve from 0.29422\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2324 - accuracy: 0.9146 - val_loss: 0.2961 - val_accuracy: 0.8976\n",
            "Epoch 49/100\n",
            "1863/1875 [============================>.] - ETA: 0s - loss: 0.2281 - accuracy: 0.9164\n",
            "Epoch 49: val_loss did not improve from 0.29422\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2279 - accuracy: 0.9165 - val_loss: 0.2969 - val_accuracy: 0.8984\n",
            "Epoch 50/100\n",
            "1866/1875 [============================>.] - ETA: 0s - loss: 0.2289 - accuracy: 0.9158\n",
            "Epoch 50: val_loss improved from 0.29422 to 0.29385, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2291 - accuracy: 0.9157 - val_loss: 0.2938 - val_accuracy: 0.8964\n",
            "Epoch 51/100\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.2271 - accuracy: 0.9165\n",
            "Epoch 51: val_loss improved from 0.29385 to 0.29252, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2271 - accuracy: 0.9165 - val_loss: 0.2925 - val_accuracy: 0.8938\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.2253 - accuracy: 0.9166\n",
            "Epoch 52: val_loss did not improve from 0.29252\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2253 - accuracy: 0.9166 - val_loss: 0.2955 - val_accuracy: 0.8983\n",
            "Epoch 53/100\n",
            "1869/1875 [============================>.] - ETA: 0s - loss: 0.2229 - accuracy: 0.9189\n",
            "Epoch 53: val_loss improved from 0.29252 to 0.29106, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2227 - accuracy: 0.9189 - val_loss: 0.2911 - val_accuracy: 0.8969\n",
            "Epoch 54/100\n",
            "1863/1875 [============================>.] - ETA: 0s - loss: 0.2195 - accuracy: 0.9188\n",
            "Epoch 54: val_loss did not improve from 0.29106\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2198 - accuracy: 0.9187 - val_loss: 0.2940 - val_accuracy: 0.8985\n",
            "Epoch 55/100\n",
            "1869/1875 [============================>.] - ETA: 0s - loss: 0.2199 - accuracy: 0.9187\n",
            "Epoch 55: val_loss did not improve from 0.29106\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2198 - accuracy: 0.9187 - val_loss: 0.2962 - val_accuracy: 0.8983\n",
            "Epoch 56/100\n",
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.2202 - accuracy: 0.9200\n",
            "Epoch 56: val_loss did not improve from 0.29106\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2199 - accuracy: 0.9201 - val_loss: 0.2967 - val_accuracy: 0.8975\n",
            "Epoch 57/100\n",
            "1864/1875 [============================>.] - ETA: 0s - loss: 0.2158 - accuracy: 0.9196\n",
            "Epoch 57: val_loss improved from 0.29106 to 0.29034, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2158 - accuracy: 0.9196 - val_loss: 0.2903 - val_accuracy: 0.8992\n",
            "Epoch 58/100\n",
            "1862/1875 [============================>.] - ETA: 0s - loss: 0.2179 - accuracy: 0.9203\n",
            "Epoch 58: val_loss did not improve from 0.29034\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2179 - accuracy: 0.9204 - val_loss: 0.2940 - val_accuracy: 0.8965\n",
            "Epoch 59/100\n",
            "1863/1875 [============================>.] - ETA: 0s - loss: 0.2123 - accuracy: 0.9209\n",
            "Epoch 59: val_loss did not improve from 0.29034\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2122 - accuracy: 0.9209 - val_loss: 0.3033 - val_accuracy: 0.8953\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.2157 - accuracy: 0.9207\n",
            "Epoch 60: val_loss did not improve from 0.29034\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2157 - accuracy: 0.9207 - val_loss: 0.3026 - val_accuracy: 0.8976\n",
            "Epoch 61/100\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.2113 - accuracy: 0.9233\n",
            "Epoch 61: val_loss did not improve from 0.29034\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2115 - accuracy: 0.9232 - val_loss: 0.2978 - val_accuracy: 0.8984\n",
            "Epoch 62/100\n",
            "1866/1875 [============================>.] - ETA: 0s - loss: 0.2104 - accuracy: 0.9225\n",
            "Epoch 62: val_loss did not improve from 0.29034\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2105 - accuracy: 0.9224 - val_loss: 0.2945 - val_accuracy: 0.8980\n",
            "Epoch 63/100\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.2092 - accuracy: 0.9222\n",
            "Epoch 63: val_loss did not improve from 0.29034\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2091 - accuracy: 0.9222 - val_loss: 0.2943 - val_accuracy: 0.9001\n",
            "Epoch 64/100\n",
            "1861/1875 [============================>.] - ETA: 0s - loss: 0.2079 - accuracy: 0.9242\n",
            "Epoch 64: val_loss did not improve from 0.29034\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2077 - accuracy: 0.9242 - val_loss: 0.2929 - val_accuracy: 0.8971\n",
            "Epoch 65/100\n",
            "1869/1875 [============================>.] - ETA: 0s - loss: 0.2085 - accuracy: 0.9235\n",
            "Epoch 65: val_loss did not improve from 0.29034\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2085 - accuracy: 0.9235 - val_loss: 0.2941 - val_accuracy: 0.8990\n",
            "Epoch 66/100\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.2074 - accuracy: 0.9235\n",
            "Epoch 66: val_loss did not improve from 0.29034\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2074 - accuracy: 0.9236 - val_loss: 0.2930 - val_accuracy: 0.8997\n",
            "Epoch 67/100\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.2056 - accuracy: 0.9245\n",
            "Epoch 67: val_loss improved from 0.29034 to 0.28990, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2056 - accuracy: 0.9245 - val_loss: 0.2899 - val_accuracy: 0.9004\n",
            "Epoch 68/100\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.2032 - accuracy: 0.9256\n",
            "Epoch 68: val_loss did not improve from 0.28990\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2033 - accuracy: 0.9255 - val_loss: 0.2929 - val_accuracy: 0.9004\n",
            "Epoch 69/100\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.2036 - accuracy: 0.9242\n",
            "Epoch 69: val_loss did not improve from 0.28990\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2034 - accuracy: 0.9243 - val_loss: 0.3007 - val_accuracy: 0.9007\n",
            "Epoch 70/100\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.2018 - accuracy: 0.9268\n",
            "Epoch 70: val_loss improved from 0.28990 to 0.28967, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2019 - accuracy: 0.9268 - val_loss: 0.2897 - val_accuracy: 0.8997\n",
            "Epoch 71/100\n",
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.1989 - accuracy: 0.9273\n",
            "Epoch 71: val_loss did not improve from 0.28967\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1994 - accuracy: 0.9271 - val_loss: 0.2971 - val_accuracy: 0.8984\n",
            "Epoch 72/100\n",
            "1862/1875 [============================>.] - ETA: 0s - loss: 0.1992 - accuracy: 0.9280\n",
            "Epoch 72: val_loss did not improve from 0.28967\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1992 - accuracy: 0.9280 - val_loss: 0.2920 - val_accuracy: 0.8974\n",
            "Epoch 73/100\n",
            "1864/1875 [============================>.] - ETA: 0s - loss: 0.1985 - accuracy: 0.9261\n",
            "Epoch 73: val_loss did not improve from 0.28967\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1985 - accuracy: 0.9262 - val_loss: 0.3000 - val_accuracy: 0.8985\n",
            "Epoch 74/100\n",
            "1862/1875 [============================>.] - ETA: 0s - loss: 0.1991 - accuracy: 0.9262\n",
            "Epoch 74: val_loss did not improve from 0.28967\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1990 - accuracy: 0.9262 - val_loss: 0.2930 - val_accuracy: 0.8996\n",
            "Epoch 75/100\n",
            "1860/1875 [============================>.] - ETA: 0s - loss: 0.1956 - accuracy: 0.9284\n",
            "Epoch 75: val_loss did not improve from 0.28967\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1957 - accuracy: 0.9284 - val_loss: 0.2989 - val_accuracy: 0.8990\n",
            "Epoch 76/100\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.1948 - accuracy: 0.9282\n",
            "Epoch 76: val_loss did not improve from 0.28967\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1949 - accuracy: 0.9283 - val_loss: 0.2966 - val_accuracy: 0.9026\n",
            "Epoch 77/100\n",
            "1861/1875 [============================>.] - ETA: 0s - loss: 0.1955 - accuracy: 0.9271\n",
            "Epoch 77: val_loss did not improve from 0.28967\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1958 - accuracy: 0.9270 - val_loss: 0.3071 - val_accuracy: 0.8978\n",
            "Epoch 78/100\n",
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.1922 - accuracy: 0.9287\n",
            "Epoch 78: val_loss did not improve from 0.28967\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1923 - accuracy: 0.9285 - val_loss: 0.2967 - val_accuracy: 0.8992\n",
            "Epoch 79/100\n",
            "1864/1875 [============================>.] - ETA: 0s - loss: 0.1915 - accuracy: 0.9290\n",
            "Epoch 79: val_loss did not improve from 0.28967\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1916 - accuracy: 0.9290 - val_loss: 0.2998 - val_accuracy: 0.8992\n",
            "Epoch 80/100\n",
            "1869/1875 [============================>.] - ETA: 0s - loss: 0.1945 - accuracy: 0.9287\n",
            "Epoch 80: val_loss did not improve from 0.28967\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1945 - accuracy: 0.9287 - val_loss: 0.2971 - val_accuracy: 0.9034\n",
            "[0.000 0.000 0.000 0.000 0.000 0.027 0.000 0.042 0.000 0.931]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qLx0gB2f1D8"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./tboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX58EHOwCFGm"
      },
      "source": [
        "## 연습문제: 그러면 위의 사례를 종합해서 가장 좋은 성능을 내는 모델을 만드세요 ~~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09Fd2dATCFGm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaab72a1-19d4-434a-8447-a5ed9514130e"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "# numpy float 출력옵션 변경\n",
        "np.set_printoptions(formatter={'float_kind': lambda x: \"{0:0.3f}\".format(x)})\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15)\n",
        "checkpoint_path = 'checkpoint.ckpt'\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, \n",
        "        save_best_only=True, \n",
        "        save_weights_only=True, \n",
        "        monitor='val_loss', \n",
        "        verbose=1)\n",
        "\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_train, y_train) ,  (x_test, y_test) = fmnist.load_data()\n",
        "\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0\n",
        "\n",
        "model = Sequential([Flatten(),\n",
        "              Dense(1024, activation=\"relu\"),\n",
        "              Dense(128, activation=\"relu\"),\n",
        "              Dense(64, activation=\"relu\"),\n",
        "              Dense(32, activation=\"relu\"),\n",
        "              Dense(10, activation=\"softmax\")])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), \n",
        "                    epochs=50, \n",
        "                    callbacks=[checkpoint, early_stopping])\n",
        "model.load_weights(checkpoint_path)\n",
        "\n",
        "model.save(\"fashion-mnist.h5\")      \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1859/1875 [============================>.] - ETA: 0s - loss: 0.4955 - accuracy: 0.8197\n",
            "Epoch 00001: val_loss improved from inf to 0.44177, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4949 - accuracy: 0.8199 - val_loss: 0.4418 - val_accuracy: 0.8416\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.3685 - accuracy: 0.8652\n",
            "Epoch 00002: val_loss improved from 0.44177 to 0.39695, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3685 - accuracy: 0.8652 - val_loss: 0.3970 - val_accuracy: 0.8587\n",
            "Epoch 3/50\n",
            "1863/1875 [============================>.] - ETA: 0s - loss: 0.3323 - accuracy: 0.8789\n",
            "Epoch 00003: val_loss improved from 0.39695 to 0.35924, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3319 - accuracy: 0.8790 - val_loss: 0.3592 - val_accuracy: 0.8716\n",
            "Epoch 4/50\n",
            "1857/1875 [============================>.] - ETA: 0s - loss: 0.3067 - accuracy: 0.8874\n",
            "Epoch 00004: val_loss did not improve from 0.35924\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3065 - accuracy: 0.8874 - val_loss: 0.3909 - val_accuracy: 0.8586\n",
            "Epoch 5/50\n",
            "1855/1875 [============================>.] - ETA: 0s - loss: 0.2899 - accuracy: 0.8912\n",
            "Epoch 00005: val_loss improved from 0.35924 to 0.34213, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2897 - accuracy: 0.8914 - val_loss: 0.3421 - val_accuracy: 0.8776\n",
            "Epoch 6/50\n",
            "1869/1875 [============================>.] - ETA: 0s - loss: 0.2742 - accuracy: 0.8986\n",
            "Epoch 00006: val_loss improved from 0.34213 to 0.33654, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2743 - accuracy: 0.8986 - val_loss: 0.3365 - val_accuracy: 0.8783\n",
            "Epoch 7/50\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.2620 - accuracy: 0.9017\n",
            "Epoch 00007: val_loss did not improve from 0.33654\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2621 - accuracy: 0.9017 - val_loss: 0.3396 - val_accuracy: 0.8847\n",
            "Epoch 8/50\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.2511 - accuracy: 0.9052\n",
            "Epoch 00008: val_loss improved from 0.33654 to 0.33363, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2509 - accuracy: 0.9053 - val_loss: 0.3336 - val_accuracy: 0.8855\n",
            "Epoch 9/50\n",
            "1869/1875 [============================>.] - ETA: 0s - loss: 0.2417 - accuracy: 0.9099\n",
            "Epoch 00009: val_loss improved from 0.33363 to 0.33246, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2419 - accuracy: 0.9098 - val_loss: 0.3325 - val_accuracy: 0.8877\n",
            "Epoch 10/50\n",
            "1863/1875 [============================>.] - ETA: 0s - loss: 0.2333 - accuracy: 0.9123\n",
            "Epoch 00010: val_loss did not improve from 0.33246\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2334 - accuracy: 0.9122 - val_loss: 0.3375 - val_accuracy: 0.8845\n",
            "Epoch 11/50\n",
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.2281 - accuracy: 0.9143\n",
            "Epoch 00011: val_loss improved from 0.33246 to 0.32538, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2281 - accuracy: 0.9143 - val_loss: 0.3254 - val_accuracy: 0.8900\n",
            "Epoch 12/50\n",
            "1864/1875 [============================>.] - ETA: 0s - loss: 0.2153 - accuracy: 0.9183\n",
            "Epoch 00012: val_loss did not improve from 0.32538\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2152 - accuracy: 0.9183 - val_loss: 0.3428 - val_accuracy: 0.8805\n",
            "Epoch 13/50\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.2112 - accuracy: 0.9209\n",
            "Epoch 00013: val_loss did not improve from 0.32538\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2112 - accuracy: 0.9210 - val_loss: 0.3383 - val_accuracy: 0.8889\n",
            "Epoch 14/50\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.2033 - accuracy: 0.9232\n",
            "Epoch 00014: val_loss did not improve from 0.32538\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2033 - accuracy: 0.9231 - val_loss: 0.3517 - val_accuracy: 0.8880\n",
            "Epoch 15/50\n",
            "1865/1875 [============================>.] - ETA: 0s - loss: 0.1994 - accuracy: 0.9256\n",
            "Epoch 00015: val_loss improved from 0.32538 to 0.32409, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1993 - accuracy: 0.9257 - val_loss: 0.3241 - val_accuracy: 0.8956\n",
            "Epoch 16/50\n",
            "1864/1875 [============================>.] - ETA: 0s - loss: 0.1921 - accuracy: 0.9270\n",
            "Epoch 00016: val_loss did not improve from 0.32409\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1920 - accuracy: 0.9270 - val_loss: 0.3379 - val_accuracy: 0.8937\n",
            "Epoch 17/50\n",
            "1859/1875 [============================>.] - ETA: 0s - loss: 0.1875 - accuracy: 0.9287\n",
            "Epoch 00017: val_loss did not improve from 0.32409\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1873 - accuracy: 0.9288 - val_loss: 0.3545 - val_accuracy: 0.8930\n",
            "Epoch 18/50\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.1825 - accuracy: 0.9303\n",
            "Epoch 00018: val_loss did not improve from 0.32409\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1825 - accuracy: 0.9303 - val_loss: 0.3551 - val_accuracy: 0.8895\n",
            "Epoch 19/50\n",
            "1864/1875 [============================>.] - ETA: 0s - loss: 0.1767 - accuracy: 0.9328\n",
            "Epoch 00019: val_loss did not improve from 0.32409\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1767 - accuracy: 0.9328 - val_loss: 0.3417 - val_accuracy: 0.8996\n",
            "Epoch 20/50\n",
            "1858/1875 [============================>.] - ETA: 0s - loss: 0.1733 - accuracy: 0.9351\n",
            "Epoch 00020: val_loss did not improve from 0.32409\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1734 - accuracy: 0.9351 - val_loss: 0.3524 - val_accuracy: 0.8940\n",
            "Epoch 21/50\n",
            "1856/1875 [============================>.] - ETA: 0s - loss: 0.1690 - accuracy: 0.9343\n",
            "Epoch 00021: val_loss did not improve from 0.32409\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1689 - accuracy: 0.9344 - val_loss: 0.3925 - val_accuracy: 0.8917\n",
            "Epoch 22/50\n",
            "1862/1875 [============================>.] - ETA: 0s - loss: 0.1637 - accuracy: 0.9383\n",
            "Epoch 00022: val_loss did not improve from 0.32409\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1636 - accuracy: 0.9383 - val_loss: 0.3912 - val_accuracy: 0.8892\n",
            "Epoch 23/50\n",
            "1861/1875 [============================>.] - ETA: 0s - loss: 0.1603 - accuracy: 0.9390\n",
            "Epoch 00023: val_loss did not improve from 0.32409\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1606 - accuracy: 0.9389 - val_loss: 0.3649 - val_accuracy: 0.8963\n",
            "Epoch 24/50\n",
            "1866/1875 [============================>.] - ETA: 0s - loss: 0.1570 - accuracy: 0.9399\n",
            "Epoch 00024: val_loss did not improve from 0.32409\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1570 - accuracy: 0.9398 - val_loss: 0.3969 - val_accuracy: 0.8963\n",
            "Epoch 25/50\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.1554 - accuracy: 0.9414\n",
            "Epoch 00025: val_loss did not improve from 0.32409\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1555 - accuracy: 0.9414 - val_loss: 0.3924 - val_accuracy: 0.8961\n",
            "Epoch 26/50\n",
            "1854/1875 [============================>.] - ETA: 0s - loss: 0.1516 - accuracy: 0.9416\n",
            "Epoch 00026: val_loss did not improve from 0.32409\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1518 - accuracy: 0.9416 - val_loss: 0.3836 - val_accuracy: 0.8962\n",
            "Epoch 27/50\n",
            "1860/1875 [============================>.] - ETA: 0s - loss: 0.1452 - accuracy: 0.9441\n",
            "Epoch 00027: val_loss did not improve from 0.32409\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1455 - accuracy: 0.9440 - val_loss: 0.3901 - val_accuracy: 0.9004\n",
            "Epoch 28/50\n",
            "1865/1875 [============================>.] - ETA: 0s - loss: 0.1439 - accuracy: 0.9455\n",
            "Epoch 00028: val_loss did not improve from 0.32409\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1438 - accuracy: 0.9455 - val_loss: 0.4086 - val_accuracy: 0.8948\n",
            "Epoch 29/50\n",
            "1863/1875 [============================>.] - ETA: 0s - loss: 0.1436 - accuracy: 0.9459\n",
            "Epoch 00029: val_loss did not improve from 0.32409\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1436 - accuracy: 0.9458 - val_loss: 0.4393 - val_accuracy: 0.8959\n",
            "Epoch 30/50\n",
            "1863/1875 [============================>.] - ETA: 0s - loss: 0.1410 - accuracy: 0.9469\n",
            "Epoch 00030: val_loss did not improve from 0.32409\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1409 - accuracy: 0.9470 - val_loss: 0.3987 - val_accuracy: 0.8984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw5vYyMh2fUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdd72a9a-9893-4719-bf97-4a186a64787d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_7 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1024)              803840    \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 1,083,338\n",
            "Trainable params: 1,083,338\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65GzVUDKWLkr"
      },
      "source": [
        "# 같은 Fashion Mnist 를 CNN으로 구현해 보자\n",
        "### 결과가 어떻게 될까요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izQe6N0fJzYa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "234d8798-b6a5-4c9d-e367-c1e261e24655"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
        "checkpoint_path = 'checkpoint.ckpt'\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, \n",
        "        save_best_only=True, \n",
        "        save_weights_only=True, \n",
        "        monitor='val_loss', \n",
        "        verbose=1)\n",
        "\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fmnist.load_data()\n",
        "x_train = x_train.reshape(60000, 28,28,1)\n",
        "x_test = x_test.reshape(10000, 28,28,1)\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0\n",
        "\n",
        "model = Sequential([\n",
        "        Conv2D(32, (2,2), padding='same', input_shape=(28, 28, 1), activation='relu'),\n",
        "        MaxPooling2D(2,2),\n",
        "        Conv2D(64, (2, 2), padding='same', activation='relu'), \n",
        "        MaxPooling2D(2, 2),\n",
        "        Flatten(), \n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(32, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), \n",
        "                    epochs=50, \n",
        "                    callbacks=[checkpoint, early_stopping])\n",
        "\n",
        "model.load_weights(checkpoint_path)\n",
        "model.save(\"fashion-mnist.h5\")      \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.5253 - accuracy: 0.8208\n",
            "Epoch 1: val_loss improved from inf to 0.32055, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 20s 4ms/step - loss: 0.5244 - accuracy: 0.8210 - val_loss: 0.3206 - val_accuracy: 0.8860\n",
            "Epoch 2/50\n",
            "1860/1875 [============================>.] - ETA: 0s - loss: 0.3443 - accuracy: 0.8783\n",
            "Epoch 2: val_loss improved from 0.32055 to 0.29188, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3446 - accuracy: 0.8783 - val_loss: 0.2919 - val_accuracy: 0.8982\n",
            "Epoch 3/50\n",
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.3048 - accuracy: 0.8923\n",
            "Epoch 3: val_loss improved from 0.29188 to 0.25877, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3045 - accuracy: 0.8924 - val_loss: 0.2588 - val_accuracy: 0.9080\n",
            "Epoch 4/50\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.2790 - accuracy: 0.9020\n",
            "Epoch 4: val_loss improved from 0.25877 to 0.25633, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2790 - accuracy: 0.9020 - val_loss: 0.2563 - val_accuracy: 0.9103\n",
            "Epoch 5/50\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.2576 - accuracy: 0.9079\n",
            "Epoch 5: val_loss improved from 0.25633 to 0.25076, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2576 - accuracy: 0.9079 - val_loss: 0.2508 - val_accuracy: 0.9099\n",
            "Epoch 6/50\n",
            "1865/1875 [============================>.] - ETA: 0s - loss: 0.2418 - accuracy: 0.9141\n",
            "Epoch 6: val_loss improved from 0.25076 to 0.24415, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2418 - accuracy: 0.9141 - val_loss: 0.2441 - val_accuracy: 0.9140\n",
            "Epoch 7/50\n",
            "1863/1875 [============================>.] - ETA: 0s - loss: 0.2297 - accuracy: 0.9184\n",
            "Epoch 7: val_loss did not improve from 0.24415\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2298 - accuracy: 0.9184 - val_loss: 0.2525 - val_accuracy: 0.9070\n",
            "Epoch 8/50\n",
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.2209 - accuracy: 0.9193\n",
            "Epoch 8: val_loss improved from 0.24415 to 0.24265, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2206 - accuracy: 0.9194 - val_loss: 0.2427 - val_accuracy: 0.9139\n",
            "Epoch 9/50\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.2101 - accuracy: 0.9247\n",
            "Epoch 9: val_loss improved from 0.24265 to 0.23917, saving model to checkpoint.ckpt\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2102 - accuracy: 0.9247 - val_loss: 0.2392 - val_accuracy: 0.9139\n",
            "Epoch 10/50\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.2003 - accuracy: 0.9274\n",
            "Epoch 10: val_loss did not improve from 0.23917\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2007 - accuracy: 0.9272 - val_loss: 0.2510 - val_accuracy: 0.9159\n",
            "Epoch 11/50\n",
            "1866/1875 [============================>.] - ETA: 0s - loss: 0.1943 - accuracy: 0.9307\n",
            "Epoch 11: val_loss did not improve from 0.23917\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1941 - accuracy: 0.9307 - val_loss: 0.2422 - val_accuracy: 0.9158\n",
            "Epoch 12/50\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.1873 - accuracy: 0.9327\n",
            "Epoch 12: val_loss did not improve from 0.23917\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1872 - accuracy: 0.9328 - val_loss: 0.2623 - val_accuracy: 0.9097\n",
            "Epoch 13/50\n",
            "1872/1875 [============================>.] - ETA: 0s - loss: 0.1815 - accuracy: 0.9358\n",
            "Epoch 13: val_loss did not improve from 0.23917\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1813 - accuracy: 0.9359 - val_loss: 0.2484 - val_accuracy: 0.9158\n",
            "Epoch 14/50\n",
            "1866/1875 [============================>.] - ETA: 0s - loss: 0.1748 - accuracy: 0.9368\n",
            "Epoch 14: val_loss did not improve from 0.23917\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1748 - accuracy: 0.9368 - val_loss: 0.2398 - val_accuracy: 0.9174\n",
            "Epoch 15/50\n",
            "1869/1875 [============================>.] - ETA: 0s - loss: 0.1689 - accuracy: 0.9395\n",
            "Epoch 15: val_loss did not improve from 0.23917\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1687 - accuracy: 0.9397 - val_loss: 0.2504 - val_accuracy: 0.9166\n",
            "Epoch 16/50\n",
            "1866/1875 [============================>.] - ETA: 0s - loss: 0.1641 - accuracy: 0.9405\n",
            "Epoch 16: val_loss did not improve from 0.23917\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1646 - accuracy: 0.9403 - val_loss: 0.2445 - val_accuracy: 0.9202\n",
            "Epoch 17/50\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.1583 - accuracy: 0.9433\n",
            "Epoch 17: val_loss did not improve from 0.23917\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1583 - accuracy: 0.9433 - val_loss: 0.2590 - val_accuracy: 0.9170\n",
            "Epoch 18/50\n",
            "1872/1875 [============================>.] - ETA: 0s - loss: 0.1554 - accuracy: 0.9435\n",
            "Epoch 18: val_loss did not improve from 0.23917\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1553 - accuracy: 0.9436 - val_loss: 0.2419 - val_accuracy: 0.9211\n",
            "Epoch 19/50\n",
            "1866/1875 [============================>.] - ETA: 0s - loss: 0.1485 - accuracy: 0.9464\n",
            "Epoch 19: val_loss did not improve from 0.23917\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1486 - accuracy: 0.9464 - val_loss: 0.2603 - val_accuracy: 0.9182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zfg3N3k0wRmO",
        "outputId": "9e4edb93-094f-47c8-e51f-07d3958fea7b"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model(\"fashion-mnist.h5\")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 32)        160       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 14, 14, 64)        8256      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 7, 7, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 3136)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               401536    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32)               128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 414,538\n",
            "Trainable params: 414,474\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh1QtC9uwWvW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d4ab6ba-222a-45d9-c1d0-91d5d5714aac"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2328 - accuracy: 0.9204\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.23280847072601318, 0.9204000234603882]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cce9q97g2j7N"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}
